{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Retrain EfficientDet-Lite0 Model for the \"Modelrailway-Cam\"\n",
        "In this jupyter-notebook, we'll retrain an EfficientDet-Lite object detection model using the TensorFlow Lite Model Maker library. Then we compile it to run on the Coral Edge TPU. All in about 15 minutes on a GPU. Please change runtime type (Laufzeittyp) to \"GPU\" in the menue.\n",
        "\n",
        "This notebook retrains the model using images defined in the \"training.csv\" file. The example uses images of a modelrailway showing locomotives and waggons. This notebook is an adapted version of the original notebook: \"Train a salad detector with TFLite Model Maker - Colaboratory (google.com)\".\n",
        "\n",
        "In the first step this notebook creates a runtime environment for Python 3.9 on CoLab because CoLab has upgraded to Python 3.10 and TensorFlow ModelMaker needs Python 3.9.\n",
        "\n",
        "The second step runs the training and the third step compiles the resulting tflite-model for the USB Accelarator.\n",
        "\n",
        "Author: Detlef Heinze Version: 1.2"
      ],
      "metadata": {
        "id": "_GENA5SnuBrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Create runtime environment for Python 3.9 and ModelMaker\n",
        "Thanks to https://github.com/tomkuzma for helping creating this runtime environment"
      ],
      "metadata": {
        "id": "WlOgrPySvDUS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PM6pXpLBqe6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NVxia8nLvY3",
        "outputId": "323a8fd3-ec8c-4273-8c15-51d5c23efb40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=# /env/python\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH = # /env/python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If asked to proceed in the next step click besides the question and answer \"y\"."
      ],
      "metadata": {
        "id": "DcHMOdx0yNSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
        "!./Miniconda3-py39_23.3.1-0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda update conda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gVW9AcAL1JT",
        "outputId": "92adb2a3-99ca-4c8a-d54c-56542cb38915"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-24 08:32:39--  https://repo.anaconda.com/miniconda/Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70605094 (67M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py39_23.3.1-0-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-py39_23. 100%[===================>]  67.33M   159MB/s    in 0.4s    \n",
            "\n",
            "2024-09-24 08:32:39 (159 MB/s) - ‘Miniconda3-py39_23.3.1-0-Linux-x86_64.sh’ saved [70605094/70605094]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "                                                                               \n",
            "Installing base environment...\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 23.3.1\n",
            "  latest version: 24.7.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "Or to minimize the number of packages updated during conda update use\n",
            "\n",
            "     conda install conda=24.7.1\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    brotli-python-1.0.9        |   py39h6a678d5_8         359 KB\n",
            "    ca-certificates-2024.7.2   |       h06a4308_0         127 KB\n",
            "    certifi-2024.8.30          |   py39h06a4308_0         162 KB\n",
            "    cffi-1.17.1                |   py39h1fdaa30_0         252 KB\n",
            "    charset-normalizer-3.3.2   |     pyhd3eb1b0_0          44 KB\n",
            "    conda-package-handling-2.3.0|   py39h06a4308_0         269 KB\n",
            "    conda-package-streaming-0.10.0|   py39h06a4308_0          27 KB\n",
            "    cryptography-43.0.0        |   py39hdda0065_0         2.2 MB\n",
            "    idna-3.7                   |   py39h06a4308_0         113 KB\n",
            "    jsonpatch-1.33             |   py39h06a4308_1          31 KB\n",
            "    libffi-3.4.4               |       h6a678d5_1         141 KB\n",
            "    lz4-c-1.9.4                |       h6a678d5_1         156 KB\n",
            "    openssl-3.0.15             |       h5eee18b_0         5.2 MB\n",
            "    packaging-24.1             |   py39h06a4308_0         147 KB\n",
            "    pycosat-0.6.6              |   py39h5eee18b_1          93 KB\n",
            "    pyopenssl-24.2.1           |   py39h06a4308_0          96 KB\n",
            "    python-3.9.19              |       h955ad1f_1        25.1 MB\n",
            "    requests-2.32.3            |   py39h06a4308_0          99 KB\n",
            "    sqlite-3.45.3              |       h5eee18b_0         1.2 MB\n",
            "    tk-8.6.14                  |       h39e8969_0         3.4 MB\n",
            "    tqdm-4.66.5                |   py39h2f386ee_0         133 KB\n",
            "    tzdata-2024a               |       h04d1e81_0         116 KB\n",
            "    urllib3-2.2.2              |   py39h06a4308_0         177 KB\n",
            "    xz-5.4.6                   |       h5eee18b_1         643 KB\n",
            "    zlib-1.2.13                |       h5eee18b_1         111 KB\n",
            "    zstandard-0.22.0           |   py39h2c38b39_0         427 KB\n",
            "    zstd-1.5.5                 |       hc292b87_2         643 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        41.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  brotli-python      pkgs/main/linux-64::brotli-python-1.0.9-py39h6a678d5_8 \n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1 \n",
            "  zstd               pkgs/main/linux-64::zstd-1.5.5-hc292b87_2 \n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  brotlipy-0.7.0-py39h27cfd23_1003\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                     2023.01.10-h06a4308_0 --> 2024.7.2-h06a4308_0 \n",
            "  certifi                          2022.12.7-py39h06a4308_0 --> 2024.8.30-py39h06a4308_0 \n",
            "  cffi                                1.15.1-py39h5eee18b_3 --> 1.17.1-py39h1fdaa30_0 \n",
            "  charset-normalizer                     2.0.4-pyhd3eb1b0_0 --> 3.3.2-pyhd3eb1b0_0 \n",
            "  conda-package-han~                   2.0.2-py39h06a4308_0 --> 2.3.0-py39h06a4308_0 \n",
            "  conda-package-str~                   0.7.0-py39h06a4308_0 --> 0.10.0-py39h06a4308_0 \n",
            "  cryptography                        39.0.1-py39h9ce1e76_0 --> 43.0.0-py39hdda0065_0 \n",
            "  idna                                   3.4-py39h06a4308_0 --> 3.7-py39h06a4308_0 \n",
            "  jsonpatch          pkgs/main/noarch::jsonpatch-1.32-pyhd~ --> pkgs/main/linux-64::jsonpatch-1.33-py39h06a4308_1 \n",
            "  libffi                                   3.4.2-h6a678d5_6 --> 3.4.4-h6a678d5_1 \n",
            "  openssl                                 1.1.1t-h7f8727e_0 --> 3.0.15-h5eee18b_0 \n",
            "  packaging                             23.0-py39h06a4308_0 --> 24.1-py39h06a4308_0 \n",
            "  pycosat                              0.6.4-py39h5eee18b_0 --> 0.6.6-py39h5eee18b_1 \n",
            "  pyopenssl                           23.0.0-py39h06a4308_0 --> 24.2.1-py39h06a4308_0 \n",
            "  python                                  3.9.16-h7a1cb2a_2 --> 3.9.19-h955ad1f_1 \n",
            "  requests                            2.28.1-py39h06a4308_1 --> 2.32.3-py39h06a4308_0 \n",
            "  sqlite                                  3.41.1-h5eee18b_0 --> 3.45.3-h5eee18b_0 \n",
            "  tk                                      8.6.12-h1ccaba5_0 --> 8.6.14-h39e8969_0 \n",
            "  tqdm                                4.65.0-py39hb070fc8_0 --> 4.66.5-py39h2f386ee_0 \n",
            "  tzdata                                   2023c-h04d1e81_0 --> 2024a-h04d1e81_0 \n",
            "  urllib3                            1.26.15-py39h06a4308_0 --> 2.2.2-py39h06a4308_0 \n",
            "  xz                                      5.2.10-h5eee18b_1 --> 5.4.6-h5eee18b_1 \n",
            "  zlib                                    1.2.13-h5eee18b_0 --> 1.2.13-h5eee18b_1 \n",
            "  zstandard                           0.19.0-py39h5eee18b_0 --> 0.22.0-py39h2c38b39_0 \n",
            "\n",
            "\n",
            "Proceed ([y]/n)? Y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "xz-5.4.6             | 643 KB    | :   0% 0/1 [00:00<?, ?it/s]\n",
            "jsonpatch-1.33       | 31 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "sqlite-3.45.3        | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cryptography-43.0.0  | 2.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tqdm-4.66.5          | 133 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "certifi-2024.8.30    | 162 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024a         | 116 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "packaging-24.1       | 147 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "idna-3.7             | 113 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "charset-normalizer-3 | 44 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "lz4-c-1.9.4          | 156 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.15       | 5.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-python-1.0.9  | 359 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstandard-0.22.0     | 427 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "urllib3-2.2.2        | 177 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-package-handli | 269 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "requests-2.32.3      | 99 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pycosat-0.6.6        | 93 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "xz-5.4.6             | 643 KB    | :   2% 0.02486413806395413/1 [00:00<00:04,  4.41s/it]\n",
            "\n",
            "sqlite-3.45.3        | 1.2 MB    | :   1% 0.012744531418334731/1 [00:00<00:08,  8.44s/it]\u001b[A\u001b[A\n",
            "jsonpatch-1.33       | 31 KB     | :  52% 0.5180711462450592/1 [00:00<00:00,  4.47it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tqdm-4.66.5          | 133 KB    | :  12% 0.12008648807124271/1 [00:00<00:00,  1.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "certifi-2024.8.30    | 162 KB    | :  10% 0.09862393604854147/1 [00:00<00:01,  1.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024a         | 116 KB    | :  14% 0.13760088688071623/1 [00:00<00:00,  1.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "idna-3.7             | 113 KB    | :  14% 0.1415623352946767/1 [00:00<00:01,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "packaging-24.1       | 147 KB    | :  11% 0.10867171643473993/1 [00:00<00:01,  1.73s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "jsonpatch-1.33       | 31 KB     | : 100% 1.0/1 [00:00<00:00,  4.62it/s]               \u001b[A\n",
            "jsonpatch-1.33       | 31 KB     | : 100% 1.0/1 [00:00<00:00,  4.62it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "lz4-c-1.9.4          | 156 KB    | :  10% 0.10272422332988496/1 [00:00<00:01,  2.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "charset-normalizer-3 | 44 KB     | :  36% 0.3598111342923026/1 [00:00<00:00,  1.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.15       | 5.2 MB    | :   0% 0.003007460830410892/1 [00:00<01:10, 71.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-python-1.0.9  | 359 KB    | :   4% 0.044590078272134466/1 [00:00<00:04,  4.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstandard-0.22.0     | 427 KB    | :   4% 0.037430235241169604/1 [00:00<00:05,  6.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "urllib3-2.2.2        | 177 KB    | :   9% 0.09037653210948446/1 [00:00<00:02,  2.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-package-handli | 269 KB    | :   6% 0.05940967437812749/1 [00:00<00:03,  4.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :   0% 0.0006225909938929538/1 [00:00<07:21, 441.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "requests-2.32.3      | 99 KB     | :  16% 0.16210226373278455/1 [00:00<00:01,  1.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pycosat-0.6.6        | 93 KB     | :  17% 0.17122672073239553/1 [00:00<00:01,  1.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.15       | 5.2 MB    | :  32% 0.31578338719314364/1 [00:00<00:00,  1.26it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :   6% 0.06350428137708129/1 [00:00<00:04,  4.65s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.15       | 5.2 MB    | :  52% 0.5232981844914951/1 [00:00<00:00,  1.54it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  12% 0.12016006182134009/1 [00:00<00:02,  3.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.15       | 5.2 MB    | :  83% 0.8300591891934062/1 [00:00<00:00,  2.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tqdm-4.66.5          | 133 KB    | : 100% 1.0/1 [00:00<00:00,  1.79it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tqdm-4.66.5          | 133 KB    | : 100% 1.0/1 [00:00<00:00,  1.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  21% 0.2104357559358184/1 [00:00<00:01,  1.96s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "certifi-2024.8.30    | 162 KB    | : 100% 1.0/1 [00:00<00:00,  1.66it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "certifi-2024.8.30    | 162 KB    | : 100% 1.0/1 [00:00<00:00,  1.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-5.4.6             | 643 KB    | : 100% 1.0/1 [00:00<00:00,  1.32it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  41% 0.4077971009998848/1 [00:00<00:00,  1.32s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  50% 0.5036761140593997/1 [00:00<00:00,  1.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  62% 0.6163650839540243/1 [00:00<00:00,  1.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  71% 0.7122440970135392/1 [00:01<00:00,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  81% 0.80936829206084/1 [00:01<00:00,  1.07s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | :  92% 0.9189443069859999/1 [00:01<00:00,  1.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024a         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.42s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cryptography-43.0.0  | 2.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.45s/it]               \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2024a         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  1.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "cryptography-43.0.0  | 2.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.45s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "idna-3.7             | 113 KB    | : 100% 1.0/1 [00:01<00:00,  1.46s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "idna-3.7             | 113 KB    | : 100% 1.0/1 [00:01<00:00,  1.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.47s/it]                 \u001b[A\u001b[A\n",
            "\n",
            "sqlite-3.45.3        | 1.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.47s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "charset-normalizer-3 | 44 KB     | : 100% 1.0/1 [00:01<00:00,  1.63s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "charset-normalizer-3 | 44 KB     | : 100% 1.0/1 [00:01<00:00,  1.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "packaging-24.1       | 147 KB    | : 100% 1.0/1 [00:01<00:00,  1.54s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "packaging-24.1       | 147 KB    | : 100% 1.0/1 [00:01<00:00,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "lz4-c-1.9.4          | 156 KB    | : 100% 1.0/1 [00:01<00:00,  1.53s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "lz4-c-1.9.4          | 156 KB    | : 100% 1.0/1 [00:01<00:00,  1.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-python-1.0.9  | 359 KB    | : 100% 1.0/1 [00:01<00:00,  1.53s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "brotli-python-1.0.9  | 359 KB    | : 100% 1.0/1 [00:01<00:00,  1.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "urllib3-2.2.2        | 177 KB    | : 100% 1.0/1 [00:01<00:00,  1.61s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "urllib3-2.2.2        | 177 KB    | : 100% 1.0/1 [00:01<00:00,  1.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-package-handli | 269 KB    | : 100% 1.0/1 [00:01<00:00,  1.60s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "conda-package-handli | 269 KB    | : 100% 1.0/1 [00:01<00:00,  1.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstandard-0.22.0     | 427 KB    | : 100% 1.0/1 [00:01<00:00,  1.65s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstandard-0.22.0     | 427 KB    | : 100% 1.0/1 [00:01<00:00,  1.65s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "requests-2.32.3      | 99 KB     | : 100% 1.0/1 [00:01<00:00,  1.69s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "requests-2.32.3      | 99 KB     | : 100% 1.0/1 [00:01<00:00,  1.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pycosat-0.6.6        | 93 KB     | : 100% 1.0/1 [00:01<00:00,  1.74s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pycosat-0.6.6        | 93 KB     | : 100% 1.0/1 [00:01<00:00,  1.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.0.15       | 5.2 MB    | : 100% 1.0/1 [00:02<00:00,  2.03it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.9.19        | 25.1 MB   | : 100% 1.0/1 [00:03<00:00,  1.02s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.9/site-packages')"
      ],
      "metadata": {
        "id": "MgdeH9uBL4B-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If asked to proceed in the next step click besides the question and answer \"y\"."
      ],
      "metadata": {
        "id": "UwdRYmS0xZMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda create -n myenv python=3.9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmexexhpL662",
        "outputId": "2f5919e8-8d3f-48fd-82fc-dc8f3be3c1ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 23.3.1\n",
            "  latest version: 24.7.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "Or to minimize the number of packages updated during conda update use\n",
            "\n",
            "     conda install conda=24.7.1\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    pip-24.2                   |   py39h06a4308_0         2.2 MB\n",
            "    setuptools-75.1.0          |   py39h06a4308_0         1.7 MB\n",
            "    wheel-0.44.0               |   py39h06a4308_0         108 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         4.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.7.2-h06a4308_0 \n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1 \n",
            "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
            "  openssl            pkgs/main/linux-64::openssl-3.0.15-h5eee18b_0 \n",
            "  pip                pkgs/main/linux-64::pip-24.2-py39h06a4308_0 \n",
            "  python             pkgs/main/linux-64::python-3.9.19-h955ad1f_1 \n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
            "  setuptools         pkgs/main/linux-64::setuptools-75.1.0-py39h06a4308_0 \n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
            "  tzdata             pkgs/main/noarch::tzdata-2024a-h04d1e81_0 \n",
            "  wheel              pkgs/main/linux-64::wheel-0.44.0-py39h06a4308_0 \n",
            "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1 \n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "wheel-0.44.0         | 108 KB    | :   0% 0/1 [00:00<?, ?it/s]\n",
            "setuptools-75.1.0    | 1.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pip-24.2             | 2.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "pip-24.2             | 2.2 MB    | :  32% 0.3192232787756873/1 [00:00<00:00,  3.19it/s]\u001b[A\u001b[A\n",
            "wheel-0.44.0         | 108 KB    | : 100% 1.0/1 [00:00<00:00,  4.45it/s]\n",
            "setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:01<00:00,  1.37s/it]                \u001b[A\n",
            "setuptools-75.1.0    | 1.7 MB    | : 100% 1.0/1 [00:01<00:00,  1.37s/it]\u001b[A\n",
            "\n",
            "pip-24.2             | 2.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]               \u001b[A\u001b[A\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "Preparing transaction: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install tflite-model-maker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFhvDQ7RL_BH",
        "outputId": "8add7be2-e46b-4a86-b5be-3875bbd9a437"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite-model-maker\n",
            "  Downloading tflite_model_maker-0.4.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting tf-models-official==2.3.0 (from tflite-model-maker)\n",
            "  Downloading tf_models_official-2.3.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting numpy<1.23.4,>=1.17.3 (from tflite-model-maker)\n",
            "  Downloading numpy-1.23.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting pillow>=7.0.0 (from tflite-model-maker)\n",
            "  Downloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting sentencepiece>=0.1.91 (from tflite-model-maker)\n",
            "  Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting tensorflow-datasets>=2.1.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow_datasets-4.9.3-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting fire>=0.3.1 (from tflite-model-maker)\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatbuffers>=2.0 (from tflite-model-maker)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting absl-py>=0.10.0 (from tflite-model-maker)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from tflite-model-maker)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl.metadata (41 kB)\n",
            "Collecting tflite-support>=0.4.2 (from tflite-model-maker)\n",
            "  Downloading tflite_support-0.4.4-cp39-cp39-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting tensorflowjs<3.19.0,>=2.4.0 (from tflite-model-maker)\n",
            "  Downloading tensorflowjs-3.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting tensorflow>=2.6.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow-2.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting numba>=0.53 (from tflite-model-maker)\n",
            "  Downloading numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting librosa==0.8.1 (from tflite-model-maker)\n",
            "  Downloading librosa-0.8.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting lxml>=4.6.1 (from tflite-model-maker)\n",
            "  Downloading lxml-5.3.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting PyYAML>=5.1 (from tflite-model-maker)\n",
            "  Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting matplotlib<3.5.0,>=3.0.3 (from tflite-model-maker)\n",
            "  Downloading matplotlib-3.4.3-cp39-cp39-manylinux1_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting six>=1.12.0 (from tflite-model-maker)\n",
            "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-addons>=0.11.2 (from tflite-model-maker)\n",
            "  Downloading tensorflow_addons-0.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting neural-structured-learning>=1.3.1 (from tflite-model-maker)\n",
            "  Downloading neural_structured_learning-1.4.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting tensorflow-model-optimization>=0.5 (from tflite-model-maker)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Collecting Cython>=0.29.13 (from tflite-model-maker)\n",
            "  Downloading Cython-3.0.11-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting scann==1.2.6 (from tflite-model-maker)\n",
            "  Downloading scann-1.2.6-cp39-cp39-manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting tensorflow-hub<0.13,>=0.7.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting audioread>=2.0.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting scipy>=1.0.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting scikit-learn!=0.19.0,>=0.14.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting joblib>=0.14 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting decorator>=3.0.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting soundfile>=0.10.2 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
            "Collecting pooch>=1.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting packaging>=20.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Using cached packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting tensorflow>=2.6.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow-2.8.4-cp39-cp39-manylinux2010_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting dataclasses (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gin-config (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached gin_config-0.5.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting google-api-python-client>=1.6.7 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_api_python_client-2.146.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting google-cloud-bigquery>=0.31.0 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached google_cloud_bigquery-3.25.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting kaggle>=1.3.9 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached kaggle-1.6.17.tar.gz (82 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting opencv-python-headless (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pandas>=0.22.0 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting psutil>=5.4.3 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting py-cpuinfo>=3.3.0 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
            "Collecting tf-slim>=1.1.0 (from tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting termcolor (from fire>=0.3.1->tflite-model-maker)\n",
            "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker)\n",
            "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pyparsing>=2.2.1 (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker)\n",
            "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib<3.5.0,>=3.0.3->tflite-model-maker)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting attrs (from neural-structured-learning>=1.3.1->tflite-model-maker)\n",
            "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.53->tflite-model-maker)\n",
            "  Downloading llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting gast>=0.2.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=2.9.0 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading h5py-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting libclang>=9.0.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/myenv/lib/python3.9/site-packages (from tensorflow>=2.6.0->tflite-model-maker) (75.1.0)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt>=1.11.0 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading wrapt-1.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting tensorflow-estimator<2.9,>=2.8 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.9,>=2.8.0rc0 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading grpcio-1.66.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons>=0.11.2->tflite-model-maker)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting array-record (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading array_record-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (699 bytes)\n",
            "Collecting click (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting dm-tree (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting etils>=0.9.0 (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading etils-1.5.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting promise (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is looking at multiple versions of tensorflow-datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-datasets>=2.1.0 (from tflite-model-maker)\n",
            "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading tensorflow_datasets-4.9.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading tensorflow_datasets-4.9.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting requests>=2.19.0 (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting toml (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting tqdm (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting absl-py>=0.10.0 (from tflite-model-maker)\n",
            "  Using cached absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting packaging>=20.0 (from librosa==0.8.1->tflite-model-maker)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Collecting sounddevice>=0.4.4 (from tflite-support>=0.4.2->tflite-model-maker)\n",
            "  Downloading sounddevice-0.5.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pybind11>=2.6.0 (from tflite-support>=0.4.2->tflite-model-maker)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.6.0->tflite-model-maker) (0.44.0)\n",
            "Collecting fsspec (from etils[enp,epath]>=0.9.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting importlib_resources (from etils[enp,epath]>=0.9.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting zipp (from etils[enp,epath]>=0.9.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached zipp-3.20.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_api_core-2.20.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting google-cloud-core<3.0.0dev,>=1.6.0 (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting google-resumable-media<3.0dev,>=0.6.0 (from google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting certifi>=2023.7.22 (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting python-slugify (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting bleach (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached bleach-6.1.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=0.22.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.22.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting platformdirs>=2.5.0 (from pooch>=1.0->librosa==0.8.1->tflite-model-maker)\n",
            "  Using cached platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.1->tflite-model-maker)\n",
            "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->tflite-support>=0.4.2->tflite-model-maker)\n",
            "  Downloading cffi-1.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Collecting werkzeug>=0.11.15 (from tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "INFO: pip is looking at multiple versions of tensorflow-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "  Downloading tensorflow_metadata-1.13.0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support>=0.4.2->tflite-model-maker)\n",
            "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting google-crc32c<2.0dev,>=1.0 (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading google_crc32c-1.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "INFO: pip is looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow-datasets>=2.1.0->tflite-model-maker)\n",
            "  Downloading googleapis_common_protos-1.64.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting webencodings (from bleach->kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting text-unidecode>=1.3 (from python-slugify->kaggle>=1.3.9->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
            "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery>=0.31.0->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.62.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.61.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.60.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.5-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.58.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.58.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.56.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.55.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.54.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.53.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.51.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.51.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.50.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading grpcio_status-1.49.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Using cached grpcio_status-1.48.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.3.0->tflite-model-maker)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow>=2.6.0->tflite-model-maker)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Downloading tflite_model_maker-0.4.3-py3-none-any.whl (580 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m580.1/580.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
            "Downloading scann-1.2.6-cp39-cp39-manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m120.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Cython-3.0.11-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading lxml-5.3.0-cp39-cp39-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.4.3-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
            "Downloading numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m134.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading tensorflow-2.8.4-cp39-cp39-manylinux2010_x86_64.whl (498.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_addons-0.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_datasets-4.9.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "Downloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "Downloading tflite_support-0.4.4-cp39-cp39-manylinux2014_x86_64.whl (60.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
            "Downloading etils-1.5.2-py3-none-any.whl (140 kB)\n",
            "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading google_api_python_client-2.146.0-py2.py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m135.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached google_cloud_bigquery-3.25.0-py2.py3-none-any.whl (239 kB)\n",
            "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Downloading grpcio-1.66.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m130.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h5py-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "Downloading llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
            "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.0-py3-none-any.whl (32 kB)\n",
            "Using cached soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading wrapt-1.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "Downloading array_record-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "Downloading tensorflow_metadata-1.13.0-py3-none-any.whl (53 kB)\n",
            "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "Downloading cffi-1.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (445 kB)\n",
            "Downloading charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "Downloading google_api_core-2.20.0-py3-none-any.whl (142 kB)\n",
            "Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
            "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
            "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
            "Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
            "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Using cached platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
            "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m110.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
            "Using cached bleach-6.1.0-py3-none-any.whl (162 kB)\n",
            "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Using cached zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading google_crc32c-1.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37 kB)\n",
            "Using cached grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
            "Using cached importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Using cached proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
            "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Building wheels for collected packages: fire, kaggle, promise\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=62c8dd1a13087604f2556117a36901b89497bc78d13c5c6b6141b3c88146dbc2\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/ce/ba/9d5764d2266c500c18776c7d8f1e3c023075994cbc6dea47db\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105786 sha256=b55c9a562aaca6b220c0219e703e0e8daa5b3e46044064924fd664bb6dc4673c\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/af/a9/70bffa2773af622d2ebea9c8d407720b86e67bd40c465bf837\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21483 sha256=ebf420ad543cb6272343da052def2c5075ff986784fcf07ee4c9efd48a221b6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
            "Successfully built fire kaggle promise\n",
            "Installing collected packages: webencodings, text-unidecode, tensorflow-estimator, tensorboard-plugin-wit, sentencepiece, pytz, py-cpuinfo, libclang, keras, gin-config, flatbuffers, dm-tree, dataclasses, zipp, wrapt, urllib3, uritemplate, tzdata, typing-extensions, typeguard, tqdm, toml, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, six, PyYAML, python-slugify, pyparsing, pycparser, pybind11, pyasn1, psutil, protobuf, platformdirs, pillow, oauthlib, numpy, MarkupSafe, lxml, llvmlite, kiwisolver, joblib, idna, grpcio, google-crc32c, gast, fsspec, etils, decorator, Cython, cycler, click, charset-normalizer, certifi, cachetools, audioread, attrs, absl-py, werkzeug, tf-slim, tensorflow-model-optimization, tensorflow-hub, scipy, rsa, requests, python-dateutil, pyasn1-modules, proto-plus, promise, packaging, opt-einsum, opencv-python-headless, numba, keras-preprocessing, importlib_resources, importlib-metadata, httplib2, h5py, googleapis-common-protos, google-resumable-media, google-pasta, fire, CFFI, bleach, astunparse, tensorflow-metadata, tensorflow-addons, soundfile, sounddevice, scikit-learn, resampy, requests-oauthlib, pooch, pandas, neural-structured-learning, matplotlib, markdown, kaggle, grpcio-status, google-auth, tflite-support, librosa, google-auth-oauthlib, google-auth-httplib2, google-api-core, array-record, tensorflow-datasets, tensorboard, google-cloud-core, google-api-python-client, tensorflow, google-cloud-bigquery, tf-models-official, tensorflowjs, scann, tflite-model-maker\n",
            "Successfully installed CFFI-1.17.1 Cython-3.0.11 MarkupSafe-2.1.5 PyYAML-6.0.2 absl-py-1.4.0 array-record-0.5.1 astunparse-1.6.3 attrs-24.2.0 audioread-3.0.1 bleach-6.1.0 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.3.2 click-8.1.7 cycler-0.12.1 dataclasses-0.6 decorator-5.1.1 dm-tree-0.1.8 etils-1.5.2 fire-0.6.0 flatbuffers-24.3.25 fsspec-2024.9.0 gast-0.6.0 gin-config-0.5.0 google-api-core-2.20.0 google-api-python-client-2.146.0 google-auth-2.35.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-0.4.6 google-cloud-bigquery-3.25.0 google-cloud-core-2.4.1 google-crc32c-1.6.0 google-pasta-0.2.0 google-resumable-media-2.7.2 googleapis-common-protos-1.63.1 grpcio-1.66.1 grpcio-status-1.48.2 h5py-3.11.0 httplib2-0.22.0 idna-3.10 importlib-metadata-8.5.0 importlib_resources-6.4.5 joblib-1.4.2 kaggle-1.6.17 keras-2.8.0 keras-preprocessing-1.1.2 kiwisolver-1.4.7 libclang-18.1.1 librosa-0.8.1 llvmlite-0.43.0 lxml-5.3.0 markdown-3.7 matplotlib-3.4.3 neural-structured-learning-1.4.0 numba-0.60.0 numpy-1.23.3 oauthlib-3.2.2 opencv-python-headless-4.10.0.84 opt-einsum-3.3.0 packaging-20.9 pandas-2.2.3 pillow-10.4.0 platformdirs-4.3.6 pooch-1.8.2 promise-2.3 proto-plus-1.24.0 protobuf-3.19.6 psutil-6.0.0 py-cpuinfo-9.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pybind11-2.13.6 pycparser-2.22 pyparsing-3.1.4 python-dateutil-2.9.0.post0 python-slugify-8.0.4 pytz-2024.2 requests-2.32.3 requests-oauthlib-2.0.0 resampy-0.4.3 rsa-4.9 scann-1.2.6 scikit-learn-1.5.2 scipy-1.13.1 sentencepiece-0.2.0 six-1.16.0 sounddevice-0.5.0 soundfile-0.12.1 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.4 tensorflow-addons-0.23.0 tensorflow-datasets-4.9.0 tensorflow-estimator-2.8.0 tensorflow-hub-0.12.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-metadata-1.13.0 tensorflow-model-optimization-0.8.0 tensorflowjs-3.18.0 termcolor-2.4.0 text-unidecode-1.3 tf-models-official-2.3.0 tf-slim-1.1.0 tflite-model-maker-0.4.3 tflite-support-0.4.4 threadpoolctl-3.5.0 toml-0.10.2 tqdm-4.66.5 typeguard-2.13.3 typing-extensions-4.12.2 tzdata-2024.2 uritemplate-4.1.1 urllib3-1.25.11 webencodings-0.5.1 werkzeug-3.0.4 wrapt-1.16.0 zipp-3.20.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "iR1nI9CjMB9_",
        "outputId": "a331782f-fab6-4bf1-fa9b-f366ee30bb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-636f7e70c0f3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install ipykernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnLjxOE7MUqa",
        "outputId": "f1ff2b68-9e54-4e1b-d76a-ba9911c80da8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipykernel in /usr/local/envs/myenv/lib/python3.9/site-packages (6.29.5)\n",
            "Requirement already satisfied: comm>=0.1.1 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (0.2.2)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (1.8.5)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (8.18.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (8.6.3)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (5.7.2)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (20.9)\n",
            "Requirement already satisfied: psutil in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (6.0.0)\n",
            "Requirement already satisfied: pyzmq>=24 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (26.2.0)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (6.4.1)\n",
            "Requirement already satisfied: traitlets>=5.4.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipykernel) (5.14.3)\n",
            "Requirement already satisfied: decorator in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.19.1)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (3.0.47)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
            "Requirement already satisfied: stack-data in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/envs/myenv/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/envs/myenv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (8.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/envs/myenv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/envs/myenv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.6)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/envs/myenv/lib/python3.9/site-packages (from packaging->ipykernel) (3.1.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/envs/myenv/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.20.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/envs/myenv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/envs/myenv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/envs/myenv/lib/python3.9/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/myenv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.1.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (2.4.1)\n",
            "Requirement already satisfied: pure-eval in /usr/local/envs/myenv/lib/python3.9/site-packages (from stack-data->ipython>=7.23.1->ipykernel) (0.2.3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install numpy==1.23.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFuvSjpGMcd6",
        "outputId": "b834bafd-c621-4bf3-8652-5a3eb1c93536"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.23.4 in /usr/local/envs/myenv/lib/python3.9/site-packages (1.23.4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install pycocotools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-md92qy5UMh_",
        "outputId": "f4ee1c34-27f3-498a-8e86-47451a44eb62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/envs/myenv/lib/python3.9/site-packages (2.0.8)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from pycocotools) (3.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/myenv/lib/python3.9/site-packages (from pycocotools) (1.23.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/envs/myenv/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/envs/myenv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Training of the model"
      ],
      "metadata": {
        "id": "csKTIOD0sKxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda list"
      ],
      "metadata": {
        "id": "_9sSLMA8bhIk",
        "outputId": "3886e490-a7e6-4fac-9972-a08b4c019fb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# packages in environment at /usr/local:\n",
            "#\n",
            "# Name                    Version                   Build  Channel\n",
            "_libgcc_mutex             0.1                        main  \n",
            "_openmp_mutex             5.1                       1_gnu  \n",
            "absl-py                   1.4.0                    pypi_0    pypi\n",
            "array-record              0.5.1                    pypi_0    pypi\n",
            "astunparse                1.6.3                    pypi_0    pypi\n",
            "attrs                     24.2.0                   pypi_0    pypi\n",
            "audioread                 3.0.1                    pypi_0    pypi\n",
            "bleach                    6.1.0                    pypi_0    pypi\n",
            "boltons                   23.0.0           py39h06a4308_0  \n",
            "brotli-python             1.0.9            py39h6a678d5_8  \n",
            "ca-certificates           2024.7.2             h06a4308_0  \n",
            "cachetools                5.5.0                    pypi_0    pypi\n",
            "certifi                   2024.8.30        py39h06a4308_0  \n",
            "cffi                      1.17.1           py39h1fdaa30_0  \n",
            "charset-normalizer        3.3.2              pyhd3eb1b0_0  \n",
            "click                     8.1.7                    pypi_0    pypi\n",
            "conda                     23.3.1           py39h06a4308_0  \n",
            "conda-content-trust       0.1.3            py39h06a4308_0  \n",
            "conda-package-handling    2.3.0            py39h06a4308_0  \n",
            "conda-package-streaming   0.10.0           py39h06a4308_0  \n",
            "cryptography              43.0.0           py39hdda0065_0  \n",
            "cycler                    0.12.1                   pypi_0    pypi\n",
            "cython                    3.0.11                   pypi_0    pypi\n",
            "dataclasses               0.6                      pypi_0    pypi\n",
            "decorator                 5.1.1                    pypi_0    pypi\n",
            "dm-tree                   0.1.8                    pypi_0    pypi\n",
            "etils                     1.5.2                    pypi_0    pypi\n",
            "fire                      0.6.0                    pypi_0    pypi\n",
            "flatbuffers               24.3.25                  pypi_0    pypi\n",
            "fsspec                    2024.9.0                 pypi_0    pypi\n",
            "gast                      0.6.0                    pypi_0    pypi\n",
            "gin-config                0.5.0                    pypi_0    pypi\n",
            "google-api-core           2.20.0                   pypi_0    pypi\n",
            "google-api-python-client  2.146.0                  pypi_0    pypi\n",
            "google-auth               2.35.0                   pypi_0    pypi\n",
            "google-auth-httplib2      0.2.0                    pypi_0    pypi\n",
            "google-auth-oauthlib      0.4.6                    pypi_0    pypi\n",
            "google-cloud-bigquery     3.25.0                   pypi_0    pypi\n",
            "google-cloud-core         2.4.1                    pypi_0    pypi\n",
            "google-crc32c             1.6.0                    pypi_0    pypi\n",
            "google-pasta              0.2.0                    pypi_0    pypi\n",
            "google-resumable-media    2.7.2                    pypi_0    pypi\n",
            "googleapis-common-protos  1.63.1                   pypi_0    pypi\n",
            "grpcio                    1.66.1                   pypi_0    pypi\n",
            "grpcio-status             1.48.2                   pypi_0    pypi\n",
            "h5py                      3.11.0                   pypi_0    pypi\n",
            "httplib2                  0.22.0                   pypi_0    pypi\n",
            "idna                      3.7              py39h06a4308_0  \n",
            "importlib-metadata        8.5.0                    pypi_0    pypi\n",
            "importlib-resources       6.4.5                    pypi_0    pypi\n",
            "joblib                    1.4.2                    pypi_0    pypi\n",
            "jsonpatch                 1.33             py39h06a4308_1  \n",
            "jsonpointer               2.1                pyhd3eb1b0_0  \n",
            "kaggle                    1.6.17                   pypi_0    pypi\n",
            "keras                     2.8.0                    pypi_0    pypi\n",
            "keras-preprocessing       1.1.2                    pypi_0    pypi\n",
            "kiwisolver                1.4.7                    pypi_0    pypi\n",
            "ld_impl_linux-64          2.38                 h1181459_1  \n",
            "libclang                  18.1.1                   pypi_0    pypi\n",
            "libffi                    3.4.4                h6a678d5_1  \n",
            "libgcc-ng                 11.2.0               h1234567_1  \n",
            "libgomp                   11.2.0               h1234567_1  \n",
            "librosa                   0.8.1                    pypi_0    pypi\n",
            "libstdcxx-ng              11.2.0               h1234567_1  \n",
            "llvmlite                  0.43.0                   pypi_0    pypi\n",
            "lxml                      5.3.0                    pypi_0    pypi\n",
            "lz4-c                     1.9.4                h6a678d5_1  \n",
            "markdown                  3.7                      pypi_0    pypi\n",
            "markupsafe                2.1.5                    pypi_0    pypi\n",
            "matplotlib                3.4.3                    pypi_0    pypi\n",
            "ncurses                   6.4                  h6a678d5_0  \n",
            "neural-structured-learning 1.4.0                    pypi_0    pypi\n",
            "numba                     0.60.0                   pypi_0    pypi\n",
            "numpy                     1.23.3                   pypi_0    pypi\n",
            "oauthlib                  3.2.2                    pypi_0    pypi\n",
            "opencv-python-headless    4.10.0.84                pypi_0    pypi\n",
            "openssl                   3.0.15               h5eee18b_0  \n",
            "opt-einsum                3.3.0                    pypi_0    pypi\n",
            "packaging                 20.9                     pypi_0    pypi\n",
            "pandas                    2.2.3                    pypi_0    pypi\n",
            "pillow                    10.4.0                   pypi_0    pypi\n",
            "pip                       23.0.1           py39h06a4308_0  \n",
            "platformdirs              4.3.6                    pypi_0    pypi\n",
            "pluggy                    1.0.0            py39h06a4308_1  \n",
            "pooch                     1.8.2                    pypi_0    pypi\n",
            "promise                   2.3                      pypi_0    pypi\n",
            "proto-plus                1.24.0                   pypi_0    pypi\n",
            "protobuf                  3.19.6                   pypi_0    pypi\n",
            "psutil                    6.0.0                    pypi_0    pypi\n",
            "py-cpuinfo                9.0.0                    pypi_0    pypi\n",
            "pyasn1                    0.6.1                    pypi_0    pypi\n",
            "pyasn1-modules            0.4.1                    pypi_0    pypi\n",
            "pybind11                  2.13.6                   pypi_0    pypi\n",
            "pycosat                   0.6.6            py39h5eee18b_1  \n",
            "pycparser                 2.21               pyhd3eb1b0_0  \n",
            "pyopenssl                 24.2.1           py39h06a4308_0  \n",
            "pyparsing                 3.1.4                    pypi_0    pypi\n",
            "pysocks                   1.7.1            py39h06a4308_0  \n",
            "python                    3.9.19               h955ad1f_1  \n",
            "python-dateutil           2.9.0.post0              pypi_0    pypi\n",
            "python-slugify            8.0.4                    pypi_0    pypi\n",
            "pytz                      2024.2                   pypi_0    pypi\n",
            "pyyaml                    6.0.2                    pypi_0    pypi\n",
            "readline                  8.2                  h5eee18b_0  \n",
            "requests                  2.32.3           py39h06a4308_0  \n",
            "requests-oauthlib         2.0.0                    pypi_0    pypi\n",
            "resampy                   0.4.3                    pypi_0    pypi\n",
            "rsa                       4.9                      pypi_0    pypi\n",
            "ruamel.yaml               0.17.21          py39h5eee18b_0  \n",
            "ruamel.yaml.clib          0.2.6            py39h5eee18b_1  \n",
            "scann                     1.2.6                    pypi_0    pypi\n",
            "scikit-learn              1.5.2                    pypi_0    pypi\n",
            "scipy                     1.13.1                   pypi_0    pypi\n",
            "sentencepiece             0.2.0                    pypi_0    pypi\n",
            "setuptools                65.6.3           py39h06a4308_0  \n",
            "six                       1.16.0             pyhd3eb1b0_1  \n",
            "sounddevice               0.5.0                    pypi_0    pypi\n",
            "soundfile                 0.12.1                   pypi_0    pypi\n",
            "sqlite                    3.45.3               h5eee18b_0  \n",
            "tensorboard               2.8.0                    pypi_0    pypi\n",
            "tensorboard-data-server   0.6.1                    pypi_0    pypi\n",
            "tensorboard-plugin-wit    1.8.1                    pypi_0    pypi\n",
            "tensorflow                2.8.4                    pypi_0    pypi\n",
            "tensorflow-addons         0.23.0                   pypi_0    pypi\n",
            "tensorflow-datasets       4.9.0                    pypi_0    pypi\n",
            "tensorflow-estimator      2.8.0                    pypi_0    pypi\n",
            "tensorflow-hub            0.12.0                   pypi_0    pypi\n",
            "tensorflow-io-gcs-filesystem 0.37.1                   pypi_0    pypi\n",
            "tensorflow-metadata       1.13.0                   pypi_0    pypi\n",
            "tensorflow-model-optimization 0.8.0                    pypi_0    pypi\n",
            "tensorflowjs              3.18.0                   pypi_0    pypi\n",
            "termcolor                 2.4.0                    pypi_0    pypi\n",
            "text-unidecode            1.3                      pypi_0    pypi\n",
            "tf-models-official        2.3.0                    pypi_0    pypi\n",
            "tf-slim                   1.1.0                    pypi_0    pypi\n",
            "tflite-model-maker        0.4.3                    pypi_0    pypi\n",
            "tflite-support            0.4.4                    pypi_0    pypi\n",
            "threadpoolctl             3.5.0                    pypi_0    pypi\n",
            "tk                        8.6.14               h39e8969_0  \n",
            "toml                      0.10.2                   pypi_0    pypi\n",
            "toolz                     0.12.0           py39h06a4308_0  \n",
            "tqdm                      4.66.5           py39h2f386ee_0  \n",
            "typeguard                 2.13.3                   pypi_0    pypi\n",
            "typing-extensions         4.12.2                   pypi_0    pypi\n",
            "tzdata                    2024.2                   pypi_0    pypi\n",
            "uritemplate               4.1.1                    pypi_0    pypi\n",
            "urllib3                   1.25.11                  pypi_0    pypi\n",
            "webencodings              0.5.1                    pypi_0    pypi\n",
            "werkzeug                  3.0.4                    pypi_0    pypi\n",
            "wheel                     0.38.4           py39h06a4308_0  \n",
            "wrapt                     1.16.0                   pypi_0    pypi\n",
            "xz                        5.4.6                h5eee18b_1  \n",
            "zipp                      3.20.2                   pypi_0    pypi\n",
            "zlib                      1.2.13               h5eee18b_1  \n",
            "zstandard                 0.22.0           py39h2c38b39_0  \n",
            "zstd                      1.5.5                hc292b87_2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "lncHPLudg_tN",
        "outputId": "b3b0cc04-7312-4c75-d513-3e00e7f2af3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- -----------\n",
            "absl-py                       1.4.0\n",
            "array_record                  0.5.1\n",
            "astunparse                    1.6.3\n",
            "attrs                         24.2.0\n",
            "audioread                     3.0.1\n",
            "bleach                        6.1.0\n",
            "boltons                       23.0.0\n",
            "Brotli                        1.0.9\n",
            "cachetools                    5.5.0\n",
            "certifi                       2024.8.30\n",
            "cffi                          1.17.1\n",
            "charset-normalizer            3.3.2\n",
            "click                         8.1.7\n",
            "conda                         23.3.1\n",
            "conda-content-trust           0.1.3\n",
            "conda-package-handling        2.3.0\n",
            "conda_package_streaming       0.10.0\n",
            "cryptography                  43.0.0\n",
            "cycler                        0.12.1\n",
            "Cython                        3.0.11\n",
            "dataclasses                   0.6\n",
            "decorator                     5.1.1\n",
            "dm-tree                       0.1.8\n",
            "etils                         1.5.2\n",
            "fire                          0.6.0\n",
            "flatbuffers                   24.3.25\n",
            "fsspec                        2024.9.0\n",
            "gast                          0.6.0\n",
            "gin-config                    0.5.0\n",
            "google-api-core               2.20.0\n",
            "google-api-python-client      2.146.0\n",
            "google-auth                   2.35.0\n",
            "google-auth-httplib2          0.2.0\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         3.25.0\n",
            "google-cloud-core             2.4.1\n",
            "google-crc32c                 1.6.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        2.7.2\n",
            "googleapis-common-protos      1.63.1\n",
            "grpcio                        1.66.1\n",
            "grpcio-status                 1.48.2\n",
            "h5py                          3.11.0\n",
            "httplib2                      0.22.0\n",
            "idna                          3.7\n",
            "importlib_metadata            8.5.0\n",
            "importlib_resources           6.4.5\n",
            "joblib                        1.4.2\n",
            "jsonpatch                     1.33\n",
            "jsonpointer                   2.1\n",
            "kaggle                        1.6.17\n",
            "keras                         2.8.0\n",
            "Keras-Preprocessing           1.1.2\n",
            "kiwisolver                    1.4.7\n",
            "libclang                      18.1.1\n",
            "librosa                       0.8.1\n",
            "llvmlite                      0.43.0\n",
            "lxml                          5.3.0\n",
            "Markdown                      3.7\n",
            "MarkupSafe                    2.1.5\n",
            "matplotlib                    3.4.3\n",
            "neural-structured-learning    1.4.0\n",
            "numba                         0.60.0\n",
            "numpy                         1.23.3\n",
            "oauthlib                      3.2.2\n",
            "opencv-python-headless        4.10.0.84\n",
            "opt-einsum                    3.3.0\n",
            "packaging                     20.9\n",
            "pandas                        2.2.3\n",
            "pillow                        10.4.0\n",
            "pip                           23.0.1\n",
            "platformdirs                  4.3.6\n",
            "pluggy                        1.0.0\n",
            "pooch                         1.8.2\n",
            "promise                       2.3\n",
            "proto-plus                    1.24.0\n",
            "protobuf                      3.19.6\n",
            "psutil                        6.0.0\n",
            "py-cpuinfo                    9.0.0\n",
            "pyasn1                        0.6.1\n",
            "pyasn1_modules                0.4.1\n",
            "pybind11                      2.13.6\n",
            "pycosat                       0.6.6\n",
            "pycparser                     2.21\n",
            "pyOpenSSL                     24.2.1\n",
            "pyparsing                     3.1.4\n",
            "PySocks                       1.7.1\n",
            "python-dateutil               2.9.0.post0\n",
            "python-slugify                8.0.4\n",
            "pytz                          2024.2\n",
            "PyYAML                        6.0.2\n",
            "requests                      2.32.3\n",
            "requests-oauthlib             2.0.0\n",
            "resampy                       0.4.3\n",
            "rsa                           4.9\n",
            "ruamel.yaml                   0.17.21\n",
            "ruamel.yaml.clib              0.2.6\n",
            "scann                         1.2.6\n",
            "scikit-learn                  1.5.2\n",
            "scipy                         1.13.1\n",
            "sentencepiece                 0.2.0\n",
            "setuptools                    65.6.3\n",
            "six                           1.16.0\n",
            "sounddevice                   0.5.0\n",
            "soundfile                     0.12.1\n",
            "tensorboard                   2.8.0\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.8.4\n",
            "tensorflow-addons             0.23.0\n",
            "tensorflow-datasets           4.9.0\n",
            "tensorflow-estimator          2.8.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io-gcs-filesystem  0.37.1\n",
            "tensorflow-metadata           1.13.0\n",
            "tensorflow-model-optimization 0.8.0\n",
            "tensorflowjs                  3.18.0\n",
            "termcolor                     2.4.0\n",
            "text-unidecode                1.3\n",
            "tf-models-official            2.3.0\n",
            "tf-slim                       1.1.0\n",
            "tflite-model-maker            0.4.3\n",
            "tflite-support                0.4.4\n",
            "threadpoolctl                 3.5.0\n",
            "toml                          0.10.2\n",
            "toolz                         0.12.0\n",
            "tqdm                          4.66.5\n",
            "typeguard                     2.13.3\n",
            "typing_extensions             4.12.2\n",
            "tzdata                        2024.2\n",
            "uritemplate                   4.1.1\n",
            "urllib3                       1.25.11\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      3.0.4\n",
            "wheel                         0.38.4\n",
            "wrapt                         1.16.0\n",
            "zipp                          3.20.2\n",
            "zstandard                     0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip valid.zip"
      ],
      "metadata": {
        "id": "G97mhz-Pfcf2",
        "outputId": "c6bd7bcf-080a-414d-8431-c06e1e6bbdcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  valid.zip\n",
            "   creating: test/\n",
            "   creating: test/annotations/\n",
            "  inflating: test/annotations/trimmed_TTe8RcSi7Ac_mp4-25_jpg.rf.9f1ddf6fa7e8a4434146b6e6361c8d3a.xml  \n",
            "  inflating: test/annotations/trimmed_WWpN2S3Izp0_mp4-13_jpg.rf.d8a5189bba0ecd7223eb35120c7215db.xml  \n",
            "  inflating: test/annotations/trimmed_ZvK6LdFV7-s_mp4-15_jpg.rf.d55e5f1479df0cd6d4804c0ce016341d.xml  \n",
            "  inflating: test/annotations/trimmed_ZvK6LdFV7-s_mp4-5_jpg.rf.5ec093c3fb98a8725df8ffd6d8991219.xml  \n",
            "   creating: test/images/\n",
            "  inflating: test/images/trimmed_TTe8RcSi7Ac_mp4-25_jpg.rf.9f1ddf6fa7e8a4434146b6e6361c8d3a.jpg  \n",
            "  inflating: test/images/trimmed_WWpN2S3Izp0_mp4-13_jpg.rf.d8a5189bba0ecd7223eb35120c7215db.jpg  \n",
            "  inflating: test/images/trimmed_ZvK6LdFV7-s_mp4-15_jpg.rf.d55e5f1479df0cd6d4804c0ce016341d.jpg  \n",
            "  inflating: test/images/trimmed_ZvK6LdFV7-s_mp4-5_jpg.rf.5ec093c3fb98a8725df8ffd6d8991219.jpg  \n",
            "   creating: train/\n",
            "   creating: train/annotations/\n",
            "  inflating: train/annotations/trimmed_WWpN2S3Izp0_mp4-22_jpg.rf.63c2a41c1a4820445a19b82018207194.xml  \n",
            "  inflating: train/annotations/trimmed_WWpN2S3Izp0_mp4-26_jpg.rf.fcf91ca3f729cc469a29dc0ac1791358.xml  \n",
            "  inflating: train/annotations/trimmed_ZvK6LdFV7-s_mp4-10_jpg.rf.2aded0c0f89eca70af1bf688fa8afbd2.xml  \n",
            "  inflating: train/annotations/trimmed_ZvK6LdFV7-s_mp4-18_jpg.rf.c26735d595521ddb8fd78b510b78a2ca.xml  \n",
            "  inflating: train/annotations/trimmed_ZvK6LdFV7-s_mp4-1_jpg.rf.6bb9b432ec0249b66150f3f41c894b73.xml  \n",
            "  inflating: train/annotations/trimmed_ZvK6LdFV7-s_mp4-22_jpg.rf.8169aac0bfe3b84ca5664afa276e5370.xml  \n",
            "  inflating: train/annotations/trimmed_ZvK6LdFV7-s_mp4-24_jpg.rf.99f3e4e4dce9d7851eed72ebccfe4edc.xml  \n",
            "  inflating: train/annotations/trimmed_ZvK6LdFV7-s_mp4-2_jpg.rf.5720716cd99521f2b1b676448aa2a365.xml  \n",
            "   creating: train/images/\n",
            "  inflating: train/images/trimmed_WWpN2S3Izp0_mp4-22_jpg.rf.63c2a41c1a4820445a19b82018207194.jpg  \n",
            "  inflating: train/images/trimmed_WWpN2S3Izp0_mp4-26_jpg.rf.fcf91ca3f729cc469a29dc0ac1791358.jpg  \n",
            "  inflating: train/images/trimmed_ZvK6LdFV7-s_mp4-10_jpg.rf.2aded0c0f89eca70af1bf688fa8afbd2.jpg  \n",
            "  inflating: train/images/trimmed_ZvK6LdFV7-s_mp4-18_jpg.rf.c26735d595521ddb8fd78b510b78a2ca.jpg  \n",
            "  inflating: train/images/trimmed_ZvK6LdFV7-s_mp4-1_jpg.rf.6bb9b432ec0249b66150f3f41c894b73.jpg  \n",
            "  inflating: train/images/trimmed_ZvK6LdFV7-s_mp4-22_jpg.rf.8169aac0bfe3b84ca5664afa276e5370.jpg  \n",
            "  inflating: train/images/trimmed_ZvK6LdFV7-s_mp4-24_jpg.rf.99f3e4e4dce9d7851eed72ebccfe4edc.jpg  \n",
            "  inflating: train/images/trimmed_ZvK6LdFV7-s_mp4-2_jpg.rf.5720716cd99521f2b1b676448aa2a365.jpg  \n",
            "   creating: validate/\n",
            "   creating: validate/annotations/\n",
            "  inflating: validate/annotations/trimmed_TTe8RcSi7Ac_mp4-13_jpg.rf.16c51e078c500d07942ff3be07d71036.xml  \n",
            "  inflating: validate/annotations/trimmed_TTe8RcSi7Ac_mp4-15_jpg.rf.c4ba78c592a16f854fa53888c631631e.xml  \n",
            "  inflating: validate/annotations/trimmed_TTe8RcSi7Ac_mp4-18_jpg.rf.cc28e4c8fcb95f98df35e4c9264956e1.xml  \n",
            "   creating: validate/images/\n",
            "  inflating: validate/images/trimmed_TTe8RcSi7Ac_mp4-13_jpg.rf.16c51e078c500d07942ff3be07d71036.jpg  \n",
            "  inflating: validate/images/trimmed_TTe8RcSi7Ac_mp4-15_jpg.rf.c4ba78c592a16f854fa53888c631631e.jpg  \n",
            "  inflating: validate/images/trimmed_TTe8RcSi7Ac_mp4-18_jpg.rf.cc28e4c8fcb95f98df35e4c9264956e1.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite_model_maker"
      ],
      "metadata": {
        "id": "QgizTDPJjKEM",
        "outputId": "522d0473-7647-419c-d490-72c865499f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite_model_maker\n",
            "  Downloading tflite_model_maker-0.4.3-py3-none-any.whl (580 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m580.1/580.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.10.0\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-datasets>=2.1.0\n",
            "  Downloading tensorflow_datasets-4.9.3-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scann==1.2.6\n",
            "  Downloading scann-1.2.6-cp39-cp39-manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=7.0.0\n",
            "  Downloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba>=0.53\n",
            "  Downloading numba-0.60.0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.1.91\n",
            "  Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-addons>=0.11.2\n",
            "  Downloading tensorflow_addons-0.23.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/site-packages (from tflite_model_maker) (1.16.0)\n",
            "Collecting librosa==0.8.1\n",
            "  Downloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.8/203.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Collecting numpy<1.23.4,>=1.17.3\n",
            "  Downloading numpy-1.23.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire>=0.3.1\n",
            "  Using cached fire-0.6.0-py2.py3-none-any.whl\n",
            "Collecting tensorflow-hub<0.13,>=0.7.0\n",
            "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.8/108.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib<3.5.0,>=3.0.3\n",
            "  Downloading matplotlib-3.4.3-cp39-cp39-manylinux1_x86_64.whl (10.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow>=2.6.0\n",
            "  Downloading tensorflow-2.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.3/601.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting neural-structured-learning>=1.3.1\n",
            "  Downloading neural_structured_learning-1.4.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.6/128.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Cython>=0.29.13\n",
            "  Downloading Cython-3.0.11-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.5\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-models-official==2.3.0\n",
            "  Downloading tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/128.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tflite-support>=0.4.2\n",
            "  Downloading tflite_support-0.4.4-cp39-cp39-manylinux2014_x86_64.whl (60.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lxml>=4.6.1\n",
            "  Downloading lxml-5.3.0-cp39-cp39-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflowjs<3.19.0,>=2.4.0\n",
            "  Downloading tensorflowjs-3.18.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.0.0\n",
            "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn!=0.19.0,>=0.14.0\n",
            "  Downloading scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator>=3.0.0\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting joblib>=0.14\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting audioread>=2.0.0\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pooch>=1.0\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from librosa==0.8.1->tflite_model_maker) (24.1)\n",
            "Collecting soundfile>=0.10.2\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow>=2.6.0\n",
            "  Downloading tensorflow-2.8.4-cp39-cp39-manylinux2010_x86_64.whl (498.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.1/498.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gin-config\n",
            "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=0.22.0\n",
            "  Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-cpuinfo>=3.3.0\n",
            "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting tf-slim>=1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting google-cloud-bigquery>=0.31.0\n",
            "  Downloading google_cloud_bigquery-3.25.0-py2.py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.0/239.0 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kaggle>=1.3.9\n",
            "  Using cached kaggle-1.6.17-py3-none-any.whl\n",
            "Collecting psutil>=5.4.3\n",
            "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.5/290.5 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-python-client>=1.6.7\n",
            "  Downloading google_api_python_client-2.146.0-py2.py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor\n",
            "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Collecting pyparsing>=2.2.1\n",
            "  Downloading pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting attrs\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.44,>=0.43.0dev0\n",
            "  Downloading llvmlite-0.43.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
            "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=3.6.6\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.16.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.1/80.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py>=2.9.0\n",
            "  Downloading h5py-3.11.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.9,>=2.8\n",
            "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting libclang>=9.0.1\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.66.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting gast>=0.2.1\n",
            "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from tensorflow>=2.6.0->tflite_model_maker) (65.6.3)\n",
            "Collecting typeguard<3.0.0,>=2.7\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Collecting promise\n",
            "  Using cached promise-2.3-py3-none-any.whl\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting etils[enp,epath,etree]>=0.9.0\n",
            "  Downloading etils-1.5.2-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-tree\n",
            "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click\n",
            "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m590.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting array-record\n",
            "  Downloading array_record-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-datasets>=2.1.0\n",
            "  Downloading tensorflow_datasets-4.9.2-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow_datasets-4.9.1-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading tensorflow_datasets-4.9.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/site-packages (from tensorflow-datasets>=2.1.0->tflite_model_maker) (2.32.3)\n",
            "Collecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from tensorflow-datasets>=2.1.0->tflite_model_maker) (4.66.5)\n",
            "Collecting absl-py>=0.10.0\n",
            "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11>=2.6.0\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sounddevice>=0.4.4\n",
            "  Downloading sounddevice-0.5.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.6.0->tflite_model_maker) (0.38.4)\n",
            "Collecting zipp\n",
            "  Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib_resources\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Collecting httplib2<1.dev0,>=0.19.0\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-httplib2<1.0.0,>=0.2.0\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0\n",
            "  Downloading google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.0/209.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uritemplate<5,>=3.0.1\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5\n",
            "  Downloading google_api_core-2.20.0-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.2/142.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-resumable-media<3.0dev,>=0.6.0\n",
            "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-cloud-core<3.0.0dev,>=1.6.0\n",
            "  Downloading google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
            "Collecting bleach\n",
            "  Downloading bleach-6.1.0-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.8/162.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official==2.3.0->tflite_model_maker) (2024.8.30)\n",
            "Collecting python-slugify\n",
            "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting tzdata>=2022.7\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting platformdirs>=2.5.0\n",
            "  Downloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite_model_maker) (3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.19.0->tensorflow-datasets>=2.1.0->tflite_model_maker) (3.3.2)\n",
            "Collecting threadpoolctl>=3.1.0\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.9/site-packages (from sounddevice>=0.4.4->tflite-support>=0.4.2->tflite_model_maker) (1.17.1)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "  Downloading werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-metadata\n",
            "  Downloading tensorflow_metadata-1.14.0-py3-none-any.whl (28 kB)\n",
            "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
            "  Downloading tensorflow_metadata-1.13.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting googleapis-common-protos<2,>=1.52.0\n",
            "  Downloading googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->tflite-support>=0.4.2->tflite_model_maker) (2.21)\n",
            "Collecting proto-plus<2.0.0dev,>=1.22.3\n",
            "  Downloading proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio-status<2.0.dev0,>=1.33.2\n",
            "  Downloading grpcio_status-1.66.1-py3-none-any.whl (14 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.6.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37 kB)\n",
            "Collecting googleapis-common-protos<2,>=1.52.0\n",
            "  Downloading googleapis_common_protos-1.64.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.6/220.6 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.2/229.2 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata>=4.4\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting text-unidecode>=1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio-status<2.0.dev0,>=1.33.2\n",
            "  Downloading grpcio_status-1.66.0-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.65.5-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.65.4-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.65.2-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.65.1-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.64.3-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.64.1-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.64.0-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.63.2-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.63.0-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.62.1-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.62.0-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.61.3-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.60.2-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.60.1-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.60.0-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.59.5-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.59.3-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.59.2-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.59.0-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.58.3-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.58.0-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.57.0-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.56.2-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.56.0-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.55.3-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.54.3-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.54.2-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.54.0-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.53.2-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.53.1-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.53.0-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.51.3-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.51.1-py3-none-any.whl (5.1 kB)\n",
            "  Downloading grpcio_status-1.50.0-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.49.1-py3-none-any.whl (14 kB)\n",
            "  Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: webencodings, text-unidecode, tensorflow-estimator, tensorboard-plugin-wit, sentencepiece, pytz, py-cpuinfo, libclang, keras, gin-config, flatbuffers, dm-tree, dataclasses, zipp, wrapt, urllib3, uritemplate, tzdata, typing-extensions, typeguard, toml, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, PyYAML, python-slugify, python-dateutil, pyparsing, pybind11, pyasn1, psutil, protobuf, promise, platformdirs, pillow, oauthlib, numpy, MarkupSafe, lxml, llvmlite, kiwisolver, joblib, grpcio, google-pasta, google-crc32c, gast, fsspec, etils, decorator, Cython, cycler, click, cachetools, bleach, audioread, attrs, astunparse, absl-py, werkzeug, tf-slim, tensorflow-model-optimization, tensorflow-hub, soundfile, sounddevice, scipy, rsa, pyasn1-modules, proto-plus, pandas, packaging, opt-einsum, opencv-python-headless, numba, matplotlib, keras-preprocessing, importlib_resources, importlib-metadata, httplib2, h5py, googleapis-common-protos, google-resumable-media, fire, tflite-support, tensorflow-metadata, tensorflow-addons, scikit-learn, resampy, requests-oauthlib, pooch, neural-structured-learning, markdown, kaggle, grpcio-status, google-auth, librosa, google-auth-oauthlib, google-auth-httplib2, google-api-core, array-record, tensorflow-datasets, tensorboard, google-cloud-core, google-api-python-client, tensorflow, google-cloud-bigquery, tf-models-official, tensorflowjs, scann, tflite_model_maker\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.2.2\n",
            "    Uninstalling urllib3-2.2.2:\n",
            "      Successfully uninstalled urllib3-2.2.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "Successfully installed Cython-3.0.11 MarkupSafe-2.1.5 PyYAML-6.0.2 absl-py-1.4.0 array-record-0.5.1 astunparse-1.6.3 attrs-24.2.0 audioread-3.0.1 bleach-6.1.0 cachetools-5.5.0 click-8.1.7 cycler-0.12.1 dataclasses-0.6 decorator-5.1.1 dm-tree-0.1.8 etils-1.5.2 fire-0.6.0 flatbuffers-24.3.25 fsspec-2024.9.0 gast-0.6.0 gin-config-0.5.0 google-api-core-2.20.0 google-api-python-client-2.146.0 google-auth-2.35.0 google-auth-httplib2-0.2.0 google-auth-oauthlib-0.4.6 google-cloud-bigquery-3.25.0 google-cloud-core-2.4.1 google-crc32c-1.6.0 google-pasta-0.2.0 google-resumable-media-2.7.2 googleapis-common-protos-1.63.1 grpcio-1.66.1 grpcio-status-1.48.2 h5py-3.11.0 httplib2-0.22.0 importlib-metadata-8.5.0 importlib_resources-6.4.5 joblib-1.4.2 kaggle-1.6.17 keras-2.8.0 keras-preprocessing-1.1.2 kiwisolver-1.4.7 libclang-18.1.1 librosa-0.8.1 llvmlite-0.43.0 lxml-5.3.0 markdown-3.7 matplotlib-3.4.3 neural-structured-learning-1.4.0 numba-0.60.0 numpy-1.23.3 oauthlib-3.2.2 opencv-python-headless-4.10.0.84 opt-einsum-3.3.0 packaging-20.9 pandas-2.2.3 pillow-10.4.0 platformdirs-4.3.6 pooch-1.8.2 promise-2.3 proto-plus-1.24.0 protobuf-3.19.6 psutil-6.0.0 py-cpuinfo-9.0.0 pyasn1-0.6.1 pyasn1-modules-0.4.1 pybind11-2.13.6 pyparsing-3.1.4 python-dateutil-2.9.0.post0 python-slugify-8.0.4 pytz-2024.2 requests-oauthlib-2.0.0 resampy-0.4.3 rsa-4.9 scann-1.2.6 scikit-learn-1.5.2 scipy-1.13.1 sentencepiece-0.2.0 sounddevice-0.5.0 soundfile-0.12.1 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.4 tensorflow-addons-0.23.0 tensorflow-datasets-4.9.0 tensorflow-estimator-2.8.0 tensorflow-hub-0.12.0 tensorflow-io-gcs-filesystem-0.37.1 tensorflow-metadata-1.13.0 tensorflow-model-optimization-0.8.0 tensorflowjs-3.18.0 termcolor-2.4.0 text-unidecode-1.3 tf-models-official-2.3.0 tf-slim-1.1.0 tflite-support-0.4.4 tflite_model_maker-0.4.3 threadpoolctl-3.5.0 toml-0.10.2 typeguard-2.13.3 typing-extensions-4.12.2 tzdata-2024.2 uritemplate-4.1.1 urllib3-1.25.11 webencodings-0.5.1 werkzeug-3.0.4 wrapt-1.16.0 zipp-3.20.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "cycler",
                  "google",
                  "httplib2",
                  "kiwisolver"
                ]
              },
              "id": "a4daafbd91a248d3a1918318b95e52d9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "Z-Jy_-4MGuzV",
        "outputId": "ecbb069d-a82c-411c-f82f-1a1ba58e536b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdataset\u001b[0m/  \u001b[01;32mMiniconda3-py39_23.3.1-0-Linux-x86_64.sh\u001b[0m*  \u001b[01;34msample_data\u001b[0m/  train.py  valid.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/data_util/object_detector_dataloader.py"
      ],
      "metadata": {
        "id": "gFn8Cn1tHe9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python train.py"
      ],
      "metadata": {
        "id": "24IzEP7rlleC",
        "outputId": "74ea54cf-2f95-4d5e-d418-3fe76f8fc1df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-24 08:59:33.732580: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2024-09-24 08:59:33.732632: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "{1: 'club', 2: 'club_head', 3: 'golf_hole', 4: 'golf_mat', 5: 'golfball', 6: 'person', 7: 'player_not_ready', 8: 'player_ready'}\n",
            "train count: 0\n",
            "validation count: 0\n",
            "test count: 0\n",
            "train count: 0\n",
            "validation count: 0\n",
            "test count: 0\n",
            "2024-09-24 08:59:46.441012: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2024-09-24 08:59:46.441056: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2024-09-24 08:59:46.441101: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (084e7173b184): /proc/driver/nvidia/version does not exist\n",
            "2024-09-24 08:59:46.450048: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train.py\", line 167, in <module>\n",
            "    model = object_detector.create(train_data=train_data,\n",
            "  File \"/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/object_detector.py\", line 260, in create\n",
            "    object_detector.train(train_data, validation_data, epochs, batch_size)\n",
            "  File \"/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/object_detector.py\", line 106, in train\n",
            "    raise ValueError('The size of the train_data (%d) couldn\\'t be smaller '\n",
            "ValueError: The size of the train_data (0) couldn't be smaller than batch_size (2). To solve this problem, set the batch_size smaller or increase the size of the train_data.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'eval \"$(conda shell.bash hook)\"\nconda activate myenv\npython train.py\n' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9baf86a247e9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval \"$(conda shell.bash hook)\"\\nconda activate myenv\\npython train.py\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'eval \"$(conda shell.bash hook)\"\nconda activate myenv\npython train.py\n' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%shell\n",
        "# eval \"$(conda shell.bash hook)\"\n",
        "# conda activate myenv\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.object = object\n",
        "np.bool = bool\n",
        "np.complex = complex\n",
        "\n",
        "from tflite_model_maker import image_classifier\n",
        "\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "use_custom_dataset = True\n",
        "dataset_is_split = False\n",
        "\n",
        "if use_custom_dataset:\n",
        "\n",
        "  # The ZIP file you uploaded:\n",
        "  #!unzip dataset.zip\n",
        "\n",
        "  # Your labels map as a dictionary (zero is reserved):\n",
        "  label_map = {1: 'YM'}\n",
        "  print(label_map)\n",
        "\n",
        "  if dataset_is_split:\n",
        "    # If your dataset is already split, specify each path:\n",
        "    train_images_dir = 'dataset/train/images'\n",
        "    train_annotations_dir = 'dataset/train/annotations'\n",
        "    val_images_dir = 'dataset/validation/images'\n",
        "    val_annotations_dir = 'dataset/validation/annotations'\n",
        "    test_images_dir = 'dataset/test/images'\n",
        "    test_annotations_dir = 'dataset/test/annotations'\n",
        "  else:\n",
        "    # If it's NOT split yet, specify the path to all images and annotations\n",
        "    images_in = 'dataset/images'\n",
        "    annotations_in = 'dataset/annotations'\n",
        "\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def split_dataset(images_path, annotations_path, val_split, test_split, out_path):\n",
        "  \"\"\"Splits a directory of sorted images/annotations into training, validation, and test sets.\n",
        "\n",
        "  Args:\n",
        "    images_path: Path to the directory with your images (JPGs).\n",
        "    annotations_path: Path to a directory with your VOC XML annotation files,\n",
        "      with filenames corresponding to image filenames. This may be the same path\n",
        "      used for images_path.\n",
        "    val_split: Fraction of data to reserve for validation (float between 0 and 1).\n",
        "    test_split: Fraction of data to reserve for test (float between 0 and 1).\n",
        "  Returns:\n",
        "    The paths for the split images/annotations (train_dir, val_dir, test_dir)\n",
        "  \"\"\"\n",
        "  _, dirs, _ = next(os.walk(images_path))\n",
        "\n",
        "  train_dir = os.path.join(out_path, 'train')\n",
        "  val_dir = os.path.join(out_path, 'validation')\n",
        "  test_dir = os.path.join(out_path, 'test')\n",
        "\n",
        "  IMAGES_TRAIN_DIR = os.path.join(train_dir, 'images')\n",
        "  IMAGES_VAL_DIR = os.path.join(val_dir, 'images')\n",
        "  IMAGES_TEST_DIR = os.path.join(test_dir, 'images')\n",
        "  os.makedirs(IMAGES_TRAIN_DIR, exist_ok=True)\n",
        "  os.makedirs(IMAGES_VAL_DIR, exist_ok=True)\n",
        "  os.makedirs(IMAGES_TEST_DIR, exist_ok=True)\n",
        "\n",
        "  ANNOT_TRAIN_DIR = os.path.join(train_dir, 'annotations')\n",
        "  ANNOT_VAL_DIR = os.path.join(val_dir, 'annotations')\n",
        "  ANNOT_TEST_DIR = os.path.join(test_dir, 'annotations')\n",
        "  os.makedirs(ANNOT_TRAIN_DIR, exist_ok=True)\n",
        "  os.makedirs(ANNOT_VAL_DIR, exist_ok=True)\n",
        "  os.makedirs(ANNOT_TEST_DIR, exist_ok=True)\n",
        "\n",
        "  # Get all filenames for this dir, filtered by filetype\n",
        "  filenames = os.listdir(os.path.join(images_path))\n",
        "  filenames = [os.path.join(images_path, f) for f in filenames if (f.endswith('.jpg'))]\n",
        "  # Shuffle the files, deterministically\n",
        "  filenames.sort()\n",
        "  random.seed(42)\n",
        "  random.shuffle(filenames)\n",
        "  # Get exact number of images for validation and test; the rest is for training\n",
        "  val_count = int(len(filenames) * val_split)\n",
        "  test_count = int(len(filenames) * test_split)\n",
        "  for i, file in enumerate(filenames):\n",
        "    source_dir, filename = os.path.split(file)\n",
        "    annot_file = os.path.join(annotations_path, filename.replace(\".jpg\", \".xml\"))\n",
        "    if i < val_count:\n",
        "      shutil.copy(file, IMAGES_VAL_DIR)\n",
        "      shutil.copy(annot_file, ANNOT_VAL_DIR)\n",
        "    elif i < val_count + test_count:\n",
        "      shutil.copy(file, IMAGES_TEST_DIR)\n",
        "      shutil.copy(annot_file, ANNOT_TEST_DIR)\n",
        "    else:\n",
        "      shutil.copy(file, IMAGES_TRAIN_DIR)\n",
        "      shutil.copy(annot_file, ANNOT_TRAIN_DIR)\n",
        "  return (train_dir, val_dir, test_dir)\n",
        "\n",
        "# We need to instantiate a separate DataLoader for each split dataset\n",
        "if use_custom_dataset:\n",
        "  if dataset_is_split:\n",
        "    # train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    train_data = object_detector.DataLoader.from_coco(\n",
        "        train_images_dir, train_annotations_dir, label_map=label_map)\n",
        "    validation_data = object_detector.DataLoader.from_coco(\n",
        "        val_images_dir, val_annotations_dir, label_map=label_map)\n",
        "    test_data = object_detector.DataLoader.from_coco(\n",
        "        test_images_dir, test_annotations_dir, label_map=label_map)\n",
        "  else:\n",
        "    train_dir, val_dir, test_dir = split_dataset(images_in, annotations_in,\n",
        "                                                 val_split=0.2, test_split=0.2,\n",
        "                                                 out_path='split-dataset')\n",
        "    train_data = object_detector.DataLoader.from_coco(\n",
        "        os.path.join(train_dir, 'images'),\n",
        "        os.path.join(train_dir, 'annotations'), label_map=label_map)\n",
        "    validation_data = object_detector.DataLoader.from_coco(\n",
        "        os.path.join(val_dir, 'images'),\n",
        "        os.path.join(val_dir, 'annotations'), label_map=label_map)\n",
        "    test_data = object_detector.DataLoader.from_coco(\n",
        "        os.path.join(test_dir, 'images'),\n",
        "        os.path.join(test_dir, 'annotations'), label_map=label_map)\n",
        "\n",
        "  print(f'train count: {len(train_data)}')\n",
        "  print(f'validation count: {len(validation_data)}')\n",
        "  print(f'test count: {len(test_data)}')\n",
        "\n",
        "\n",
        "spec = model_spec.get('efficientdet_lite2')\n",
        "\n",
        "model = object_detector.create(train_data=train_data,\n",
        "                               model_spec=spec,\n",
        "                               validation_data=validation_data,\n",
        "                               epochs=100,\n",
        "                               batch_size=10,\n",
        "                               train_whole_model=True)\n",
        "\n",
        "\n",
        "TFLITE_FILENAME = 'my_tflite_model.tflite'\n",
        "LABELS_FILENAME = 'labels.txt'\n",
        "\n",
        "model.export(export_dir='.', tflite_filename=TFLITE_FILENAME, label_filename=LABELS_FILENAME,\n",
        "             export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])\n",
        "\n",
        "\n",
        "model.evaluate(test_data)\n",
        "\n",
        "model.evaluate_tflite(TFLITE_FILENAME, test_data)"
      ],
      "metadata": {
        "id": "FqDIjKZ2dVwY",
        "outputId": "bc00b5e0-277b-472d-8d9a-9b686c1d796a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tflite_model_maker'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-3a8b4c9ac2a3>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_model_maker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtflite_model_maker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantizationConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tflite_model_maker'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/TrainData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "394-vapHMdTZ",
        "outputId": "e7281f4f-78f4-4146-906a-c9640f86514c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TrainData\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkLOelIMQmiU",
        "outputId": "60fb8a81-fc88-4b58-c017-03636fabd28c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.10.0 and strictly below 2.13.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "\n",
            "Transfer-Learning\n",
            "Splitting trainng data into training-,validation- and test-data).\n",
            "\n",
            "Using an EfficientDet-Lite0 model for training with 320x320 image resolution.\n",
            "2023-06-06 08:01:42.265804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-06 08:01:42.830455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-06 08:01:42.830802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-06 08:01:42.831479: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-06 08:01:42.831813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-06 08:01:42.832111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-06 08:01:42.832329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-06 08:01:43.498144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-06 08:01:43.498545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-06 08:01:43.498811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-06-06 08:01:43.498953: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-06-06 08:01:43.499006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13786 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\n",
            "Training starts......\n",
            "Epoch 1/40\n",
            "2023-06-06 08:02:34.270008: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8700\n",
            "46/46 [==============================] - 57s 321ms/step - det_loss: 1.4458 - cls_loss: 0.8939 - box_loss: 0.0110 - reg_l2_loss: 0.0630 - loss: 1.5088 - learning_rate: 0.0090 - gradient_norm: 2.6953 - val_det_loss: 1.1428 - val_cls_loss: 0.7256 - val_box_loss: 0.0083 - val_reg_l2_loss: 0.0630 - val_loss: 1.2058\n",
            "Epoch 2/40\n",
            "46/46 [==============================] - 15s 321ms/step - det_loss: 0.7161 - cls_loss: 0.3861 - box_loss: 0.0066 - reg_l2_loss: 0.0630 - loss: 0.7792 - learning_rate: 0.0100 - gradient_norm: 3.0995 - val_det_loss: 0.7052 - val_cls_loss: 0.4088 - val_box_loss: 0.0059 - val_reg_l2_loss: 0.0631 - val_loss: 0.7682\n",
            "Epoch 3/40\n",
            "46/46 [==============================] - 13s 288ms/step - det_loss: 0.5448 - cls_loss: 0.3027 - box_loss: 0.0048 - reg_l2_loss: 0.0631 - loss: 0.6079 - learning_rate: 0.0099 - gradient_norm: 3.4595 - val_det_loss: 0.5982 - val_cls_loss: 0.3422 - val_box_loss: 0.0051 - val_reg_l2_loss: 0.0631 - val_loss: 0.6613\n",
            "Epoch 4/40\n",
            "46/46 [==============================] - 14s 303ms/step - det_loss: 0.4383 - cls_loss: 0.2352 - box_loss: 0.0041 - reg_l2_loss: 0.0632 - loss: 0.5015 - learning_rate: 0.0098 - gradient_norm: 2.8188 - val_det_loss: 0.3540 - val_cls_loss: 0.1759 - val_box_loss: 0.0036 - val_reg_l2_loss: 0.0632 - val_loss: 0.4172\n",
            "Epoch 5/40\n",
            "46/46 [==============================] - 22s 476ms/step - det_loss: 0.3911 - cls_loss: 0.2233 - box_loss: 0.0034 - reg_l2_loss: 0.0632 - loss: 0.4544 - learning_rate: 0.0097 - gradient_norm: 2.5350 - val_det_loss: 0.3200 - val_cls_loss: 0.1672 - val_box_loss: 0.0031 - val_reg_l2_loss: 0.0632 - val_loss: 0.3832\n",
            "Epoch 6/40\n",
            "46/46 [==============================] - 14s 300ms/step - det_loss: 0.3453 - cls_loss: 0.2028 - box_loss: 0.0028 - reg_l2_loss: 0.0632 - loss: 0.4085 - learning_rate: 0.0095 - gradient_norm: 2.6548 - val_det_loss: 0.2132 - val_cls_loss: 0.1500 - val_box_loss: 0.0013 - val_reg_l2_loss: 0.0633 - val_loss: 0.2765\n",
            "Epoch 7/40\n",
            "46/46 [==============================] - 14s 305ms/step - det_loss: 0.3223 - cls_loss: 0.1837 - box_loss: 0.0028 - reg_l2_loss: 0.0633 - loss: 0.3855 - learning_rate: 0.0093 - gradient_norm: 2.4168 - val_det_loss: 0.2460 - val_cls_loss: 0.1292 - val_box_loss: 0.0023 - val_reg_l2_loss: 0.0633 - val_loss: 0.3093\n",
            "Epoch 8/40\n",
            "46/46 [==============================] - 14s 308ms/step - det_loss: 0.3149 - cls_loss: 0.1787 - box_loss: 0.0027 - reg_l2_loss: 0.0633 - loss: 0.3782 - learning_rate: 0.0091 - gradient_norm: 2.4811 - val_det_loss: 0.1699 - val_cls_loss: 0.1094 - val_box_loss: 0.0012 - val_reg_l2_loss: 0.0633 - val_loss: 0.2332\n",
            "Epoch 9/40\n",
            "46/46 [==============================] - 12s 268ms/step - det_loss: 0.2644 - cls_loss: 0.1557 - box_loss: 0.0022 - reg_l2_loss: 0.0633 - loss: 0.3277 - learning_rate: 0.0089 - gradient_norm: 2.2916 - val_det_loss: 0.1777 - val_cls_loss: 0.1053 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0633 - val_loss: 0.2410\n",
            "Epoch 10/40\n",
            "46/46 [==============================] - 17s 372ms/step - det_loss: 0.2887 - cls_loss: 0.1732 - box_loss: 0.0023 - reg_l2_loss: 0.0633 - loss: 0.3520 - learning_rate: 0.0086 - gradient_norm: 2.2819 - val_det_loss: 0.2228 - val_cls_loss: 0.1349 - val_box_loss: 0.0018 - val_reg_l2_loss: 0.0633 - val_loss: 0.2861\n",
            "Epoch 11/40\n",
            "46/46 [==============================] - 14s 304ms/step - det_loss: 0.2341 - cls_loss: 0.1540 - box_loss: 0.0016 - reg_l2_loss: 0.0633 - loss: 0.2975 - learning_rate: 0.0083 - gradient_norm: 2.1505 - val_det_loss: 0.2781 - val_cls_loss: 0.2293 - val_box_loss: 9.7508e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.3414\n",
            "Epoch 12/40\n",
            "46/46 [==============================] - 16s 345ms/step - det_loss: 0.2358 - cls_loss: 0.1474 - box_loss: 0.0018 - reg_l2_loss: 0.0633 - loss: 0.2992 - learning_rate: 0.0080 - gradient_norm: 2.2100 - val_det_loss: 0.1503 - val_cls_loss: 0.1068 - val_box_loss: 8.6887e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2136\n",
            "Epoch 13/40\n",
            "46/46 [==============================] - 17s 370ms/step - det_loss: 0.2354 - cls_loss: 0.1397 - box_loss: 0.0019 - reg_l2_loss: 0.0633 - loss: 0.2987 - learning_rate: 0.0077 - gradient_norm: 2.1377 - val_det_loss: 0.1752 - val_cls_loss: 0.1063 - val_box_loss: 0.0014 - val_reg_l2_loss: 0.0633 - val_loss: 0.2385\n",
            "Epoch 14/40\n",
            "46/46 [==============================] - 12s 253ms/step - det_loss: 0.2289 - cls_loss: 0.1448 - box_loss: 0.0017 - reg_l2_loss: 0.0633 - loss: 0.2922 - learning_rate: 0.0073 - gradient_norm: 2.0214 - val_det_loss: 0.1525 - val_cls_loss: 0.1012 - val_box_loss: 0.0010 - val_reg_l2_loss: 0.0633 - val_loss: 0.2159\n",
            "Epoch 15/40\n",
            "46/46 [==============================] - 16s 356ms/step - det_loss: 0.2274 - cls_loss: 0.1336 - box_loss: 0.0019 - reg_l2_loss: 0.0633 - loss: 0.2907 - learning_rate: 0.0070 - gradient_norm: 2.1800 - val_det_loss: 0.1456 - val_cls_loss: 0.1096 - val_box_loss: 7.1978e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2090\n",
            "Epoch 16/40\n",
            "46/46 [==============================] - 14s 303ms/step - det_loss: 0.2169 - cls_loss: 0.1330 - box_loss: 0.0017 - reg_l2_loss: 0.0634 - loss: 0.2803 - learning_rate: 0.0066 - gradient_norm: 2.1367 - val_det_loss: 0.1473 - val_cls_loss: 0.1131 - val_box_loss: 6.8407e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.2106\n",
            "Epoch 17/40\n",
            "46/46 [==============================] - 13s 288ms/step - det_loss: 0.2032 - cls_loss: 0.1273 - box_loss: 0.0015 - reg_l2_loss: 0.0634 - loss: 0.2666 - learning_rate: 0.0062 - gradient_norm: 1.9692 - val_det_loss: 0.2080 - val_cls_loss: 0.1343 - val_box_loss: 0.0015 - val_reg_l2_loss: 0.0634 - val_loss: 0.2714\n",
            "Epoch 18/40\n",
            "46/46 [==============================] - 15s 330ms/step - det_loss: 0.2101 - cls_loss: 0.1388 - box_loss: 0.0014 - reg_l2_loss: 0.0634 - loss: 0.2734 - learning_rate: 0.0058 - gradient_norm: 2.2050 - val_det_loss: 0.1416 - val_cls_loss: 0.1088 - val_box_loss: 6.5544e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.2049\n",
            "Epoch 19/40\n",
            "46/46 [==============================] - 12s 262ms/step - det_loss: 0.2010 - cls_loss: 0.1303 - box_loss: 0.0014 - reg_l2_loss: 0.0634 - loss: 0.2643 - learning_rate: 0.0054 - gradient_norm: 1.9312 - val_det_loss: 0.1660 - val_cls_loss: 0.1354 - val_box_loss: 6.1175e-04 - val_reg_l2_loss: 0.0634 - val_loss: 0.2294\n",
            "Epoch 20/40\n",
            "46/46 [==============================] - 18s 401ms/step - det_loss: 0.1848 - cls_loss: 0.1229 - box_loss: 0.0012 - reg_l2_loss: 0.0634 - loss: 0.2482 - learning_rate: 0.0050 - gradient_norm: 1.8547 - val_det_loss: 0.2274 - val_cls_loss: 0.1909 - val_box_loss: 7.3102e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.2908\n",
            "Epoch 21/40\n",
            "46/46 [==============================] - 14s 306ms/step - det_loss: 0.1828 - cls_loss: 0.1190 - box_loss: 0.0013 - reg_l2_loss: 0.0633 - loss: 0.2461 - learning_rate: 0.0046 - gradient_norm: 1.8470 - val_det_loss: 0.1257 - val_cls_loss: 0.0872 - val_box_loss: 7.7090e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1891\n",
            "Epoch 22/40\n",
            "46/46 [==============================] - 13s 289ms/step - det_loss: 0.1817 - cls_loss: 0.1227 - box_loss: 0.0012 - reg_l2_loss: 0.0633 - loss: 0.2450 - learning_rate: 0.0042 - gradient_norm: 1.8723 - val_det_loss: 0.1130 - val_cls_loss: 0.0827 - val_box_loss: 6.0548e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1764\n",
            "Epoch 23/40\n",
            "46/46 [==============================] - 15s 324ms/step - det_loss: 0.1747 - cls_loss: 0.1190 - box_loss: 0.0011 - reg_l2_loss: 0.0633 - loss: 0.2381 - learning_rate: 0.0038 - gradient_norm: 1.9382 - val_det_loss: 0.1281 - val_cls_loss: 0.0996 - val_box_loss: 5.7019e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1915\n",
            "Epoch 24/40\n",
            "46/46 [==============================] - 12s 269ms/step - det_loss: 0.1802 - cls_loss: 0.1216 - box_loss: 0.0012 - reg_l2_loss: 0.0633 - loss: 0.2435 - learning_rate: 0.0034 - gradient_norm: 1.9568 - val_det_loss: 0.1256 - val_cls_loss: 0.0940 - val_box_loss: 6.3220e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1890\n",
            "Epoch 25/40\n",
            "46/46 [==============================] - 17s 376ms/step - det_loss: 0.1880 - cls_loss: 0.1257 - box_loss: 0.0012 - reg_l2_loss: 0.0633 - loss: 0.2513 - learning_rate: 0.0030 - gradient_norm: 1.9076 - val_det_loss: 0.1321 - val_cls_loss: 0.0976 - val_box_loss: 6.9160e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1955\n",
            "Epoch 26/40\n",
            "46/46 [==============================] - 14s 294ms/step - det_loss: 0.1853 - cls_loss: 0.1223 - box_loss: 0.0013 - reg_l2_loss: 0.0633 - loss: 0.2486 - learning_rate: 0.0027 - gradient_norm: 1.9434 - val_det_loss: 0.1166 - val_cls_loss: 0.0838 - val_box_loss: 6.5546e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1799\n",
            "Epoch 27/40\n",
            "46/46 [==============================] - 13s 291ms/step - det_loss: 0.1667 - cls_loss: 0.1086 - box_loss: 0.0012 - reg_l2_loss: 0.0633 - loss: 0.2300 - learning_rate: 0.0023 - gradient_norm: 1.7289 - val_det_loss: 0.1179 - val_cls_loss: 0.0773 - val_box_loss: 8.1048e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1812\n",
            "Epoch 28/40\n",
            "46/46 [==============================] - 16s 340ms/step - det_loss: 0.1563 - cls_loss: 0.1057 - box_loss: 0.0010 - reg_l2_loss: 0.0633 - loss: 0.2196 - learning_rate: 0.0020 - gradient_norm: 1.6747 - val_det_loss: 0.1012 - val_cls_loss: 0.0748 - val_box_loss: 5.2672e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1645\n",
            "Epoch 29/40\n",
            "46/46 [==============================] - 12s 264ms/step - det_loss: 0.1615 - cls_loss: 0.1108 - box_loss: 0.0010 - reg_l2_loss: 0.0633 - loss: 0.2248 - learning_rate: 0.0017 - gradient_norm: 1.8159 - val_det_loss: 0.0995 - val_cls_loss: 0.0759 - val_box_loss: 4.7285e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1628\n",
            "Epoch 30/40\n",
            "46/46 [==============================] - 17s 380ms/step - det_loss: 0.1506 - cls_loss: 0.1037 - box_loss: 9.3771e-04 - reg_l2_loss: 0.0633 - loss: 0.2139 - learning_rate: 0.0014 - gradient_norm: 1.6164 - val_det_loss: 0.1029 - val_cls_loss: 0.0733 - val_box_loss: 5.9185e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1662\n",
            "Epoch 31/40\n",
            "46/46 [==============================] - 14s 301ms/step - det_loss: 0.1613 - cls_loss: 0.1090 - box_loss: 0.0010 - reg_l2_loss: 0.0633 - loss: 0.2246 - learning_rate: 0.0011 - gradient_norm: 1.7337 - val_det_loss: 0.1001 - val_cls_loss: 0.0760 - val_box_loss: 4.8308e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1634\n",
            "Epoch 32/40\n",
            "46/46 [==============================] - 16s 359ms/step - det_loss: 0.1586 - cls_loss: 0.1111 - box_loss: 9.5073e-04 - reg_l2_loss: 0.0633 - loss: 0.2219 - learning_rate: 8.8634e-04 - gradient_norm: 1.7758 - val_det_loss: 0.1010 - val_cls_loss: 0.0753 - val_box_loss: 5.1448e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1643\n",
            "Epoch 33/40\n",
            "46/46 [==============================] - 17s 365ms/step - det_loss: 0.1573 - cls_loss: 0.1047 - box_loss: 0.0011 - reg_l2_loss: 0.0633 - loss: 0.2206 - learning_rate: 6.7118e-04 - gradient_norm: 1.5791 - val_det_loss: 0.1021 - val_cls_loss: 0.0772 - val_box_loss: 4.9747e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1654\n",
            "Epoch 34/40\n",
            "46/46 [==============================] - 13s 294ms/step - det_loss: 0.1471 - cls_loss: 0.1035 - box_loss: 8.7134e-04 - reg_l2_loss: 0.0633 - loss: 0.2104 - learning_rate: 4.8410e-04 - gradient_norm: 1.5679 - val_det_loss: 0.0979 - val_cls_loss: 0.0741 - val_box_loss: 4.7595e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1612\n",
            "Epoch 35/40\n",
            "46/46 [==============================] - 15s 329ms/step - det_loss: 0.1528 - cls_loss: 0.1022 - box_loss: 0.0010 - reg_l2_loss: 0.0633 - loss: 0.2162 - learning_rate: 3.2630e-04 - gradient_norm: 1.7394 - val_det_loss: 0.0965 - val_cls_loss: 0.0724 - val_box_loss: 4.8352e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1599\n",
            "Epoch 36/40\n",
            "46/46 [==============================] - 15s 318ms/step - det_loss: 0.1604 - cls_loss: 0.1104 - box_loss: 9.9843e-04 - reg_l2_loss: 0.0633 - loss: 0.2237 - learning_rate: 1.9881e-04 - gradient_norm: 1.7308 - val_det_loss: 0.0964 - val_cls_loss: 0.0710 - val_box_loss: 5.0772e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1597\n",
            "Epoch 37/40\n",
            "46/46 [==============================] - 13s 281ms/step - det_loss: 0.1590 - cls_loss: 0.1049 - box_loss: 0.0011 - reg_l2_loss: 0.0633 - loss: 0.2223 - learning_rate: 1.0246e-04 - gradient_norm: 1.7032 - val_det_loss: 0.0959 - val_cls_loss: 0.0710 - val_box_loss: 4.9812e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1593\n",
            "Epoch 38/40\n",
            "46/46 [==============================] - 16s 344ms/step - det_loss: 0.1599 - cls_loss: 0.1090 - box_loss: 0.0010 - reg_l2_loss: 0.0633 - loss: 0.2233 - learning_rate: 3.7871e-05 - gradient_norm: 1.7130 - val_det_loss: 0.0961 - val_cls_loss: 0.0713 - val_box_loss: 4.9557e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1594\n",
            "Epoch 39/40\n",
            "46/46 [==============================] - 12s 270ms/step - det_loss: 0.1443 - cls_loss: 0.0997 - box_loss: 8.9138e-04 - reg_l2_loss: 0.0633 - loss: 0.2076 - learning_rate: 5.4645e-06 - gradient_norm: 1.5718 - val_det_loss: 0.0963 - val_cls_loss: 0.0715 - val_box_loss: 4.9566e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1596\n",
            "Epoch 40/40\n",
            "46/46 [==============================] - 16s 340ms/step - det_loss: 0.1524 - cls_loss: 0.1051 - box_loss: 9.4543e-04 - reg_l2_loss: 0.0633 - loss: 0.2157 - learning_rate: 5.4496e-06 - gradient_norm: 1.5865 - val_det_loss: 0.0965 - val_cls_loss: 0.0718 - val_box_loss: 4.9333e-04 - val_reg_l2_loss: 0.0633 - val_loss: 0.1598\n",
            "\n",
            "Evaluating created model\n",
            "Evaluation result:\n",
            "2023-06-06 08:12:32.443095: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 63897600 exceeds 10% of free system memory.\n",
            "1/1 [==============================] - 9s 9s/step\n",
            "\n",
            "{'AP': 0.8632989,\n",
            " 'AP50': 1.0,\n",
            " 'AP75': 1.0,\n",
            " 'AP_/:Dampflok': 0.8407472,\n",
            " 'AP_/:Diesellok': 0.88585055,\n",
            " 'APl': -1.0,\n",
            " 'APm': 0.8635639,\n",
            " 'APs': -1.0,\n",
            " 'ARl': -1.0,\n",
            " 'ARm': 0.9,\n",
            " 'ARmax1': 0.875,\n",
            " 'ARmax10': 0.89807695,\n",
            " 'ARmax100': 0.9,\n",
            " 'ARs': -1.0}\n",
            "\n",
            "Export model to tflite-format\n",
            "2023-06-06 08:12:43.852294: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2023-06-06 08:13:16.649177: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n",
            "2023-06-06 08:13:23.643305: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2023-06-06 08:13:23.643351: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "2023-06-06 08:13:23.646581: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpncxn7ork\n",
            "2023-06-06 08:13:23.771816: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
            "2023-06-06 08:13:23.771880: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpncxn7ork\n",
            "2023-06-06 08:13:24.235217: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
            "2023-06-06 08:13:27.378009: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpncxn7ork\n",
            "2023-06-06 08:13:28.773300: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 5126726 microseconds.\n",
            "2023-06-06 08:13:31.106121: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-06-06 08:13:34.796244: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "\n",
            "Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0\n",
            "2023-06-06 08:15:58.767724: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "\n",
            "Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "\n",
            "\n",
            "Evaluating tflite-model\n",
            "Evaluation result:\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "52/52 [==============================] - 161s 3s/step\n",
            "\n",
            "{'AP': 0.84978133,\n",
            " 'AP50': 1.0,\n",
            " 'AP75': 1.0,\n",
            " 'AP_/:Dampflok': 0.8321963,\n",
            " 'AP_/:Diesellok': 0.8673663,\n",
            " 'APl': -1.0,\n",
            " 'APm': 0.84978133,\n",
            " 'APs': -1.0,\n",
            " 'ARl': -1.0,\n",
            " 'ARm': 0.86923075,\n",
            " 'ARmax1': 0.86923075,\n",
            " 'ARmax10': 0.86923075,\n",
            " 'ARmax100': 0.86923075,\n",
            " 'ARs': -1.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Compile tflite-model for Edge-TPU\n",
        "First we need to download the Edge TPU Compiler:"
      ],
      "metadata": {
        "id": "r959vzG-mAGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fsX8nLzXNfQ",
        "outputId": "87bd6f53-b8b4-4b83-c6d4-86a45ca7a1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2659  100  2659    0     0  75971      0 --:--:-- --:--:-- --:--:-- 78205\n",
            "OK\n",
            "deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\n",
            "Get:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:8 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,589 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [78.0 kB]\n",
            "Get:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,222 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:14 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [6,332 B]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,056 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,773 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:18 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n",
            "Ign:19 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,351 kB]\n",
            "Get:19 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [2,317 B]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,252 kB]\n",
            "Fetched 12.7 MB in 2s (6,368 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  edgetpu-compiler\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 7,913 kB of archives.\n",
            "After this operation, 31.2 MB of additional disk space will be used.\n",
            "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\n",
            "Fetched 7,913 kB in 1s (13.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package edgetpu-compiler.\n",
            "(Reading database ... 122542 files and directories currently installed.)\n",
            "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\n",
            "Unpacking edgetpu-compiler (16.0) ...\n",
            "Setting up edgetpu-compiler (16.0) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before compiling the .tflite file for the Edge TPU, it's important to consider whether your model will fit into the Edge TPU memory.\n",
        "\n",
        "The Edge TPU has approximately 8 MB of SRAM for caching model paramaters, so any model close to or over 8 MB will not fit onto the Edge TPU memory. That means the inference times are longer, because some model parameters must be fetched from the host system memory.Threrfore we choose an EfficientDetLite0 model which has the smallest memory requirements. See the file size of the resulting edgetpu.tflite-file.\n"
      ],
      "metadata": {
        "id": "mU7oX2VjmwMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TFLITE_FILENAME = 'smrc_model.tflite'\n",
        "LABELS_FILENAME = 'railwayLabels.txt'\n",
        "\n",
        "!edgetpu_compiler --min_runtime_version 13 $TFLITE_FILENAME"
      ],
      "metadata": {
        "id": "274NK4vookUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0575844f-afd0-4c93-a948-7a282150536b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Model compiled successfully in 3771 ms.\n",
            "\n",
            "Input model: smrc_model.tflite\n",
            "Input size: 4.24MiB\n",
            "Output model: smrc_model_edgetpu.tflite\n",
            "Output size: 5.57MiB\n",
            "On-chip memory used for caching model parameters: 4.21MiB\n",
            "On-chip memory remaining for caching model parameters: 3.29MiB\n",
            "Off-chip memory used for streaming uncached model parameters: 0.00B\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 267\n",
            "Operation log: smrc_model_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 264\n",
            "Number of operations that will run on CPU: 3\n",
            "See the operation log file for individual operation details.\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the files"
      ],
      "metadata": {
        "id": "wlnWO3CKsdUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#Download model and label file for edge TPU (Coral USB Accelerator)\n",
        "files.download(TFLITE_FILENAME.replace('.tflite', '_edgetpu.tflite'))\n",
        "files.download(LABELS_FILENAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "89Bn5mYosr-m",
        "outputId": "c1a5b651-cdb2-4765-df92-d84df82be172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0a406328-498d-4503-93cc-023e816a8181\", \"smrc_model_edgetpu.tflite\", 5842624)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_937b5422-d1bf-4494-9f25-713bfe54f422\", \"railwayLabels.txt\", 21)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test field"
      ],
      "metadata": {
        "id": "Qn_S2dG7ILP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/third_party/efficientdet/dataset/create_pascal_tfrecord.py"
      ],
      "metadata": {
        "id": "wArtSFZtIM1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EeUSBpqbIM-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/third_party/efficientdet/dataset/create_pascal_tfrecord.py"
      ],
      "metadata": {
        "id": "XNwlli_gIdtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2020 Google Research. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "r\"\"\"Convert PASCAL dataset to TFRecord.\n",
        "\n",
        "Example usage:\n",
        "    python create_pascal_tfrecord.py  --data_dir=/tmp/VOCdevkit  \\\n",
        "        --year=VOC2012  --output_path=/tmp/pascal\n",
        "\"\"\"\n",
        "import hashlib\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "\n",
        "from absl import app\n",
        "from absl import flags\n",
        "from absl import logging\n",
        "\n",
        "from lxml import etree\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow_examples.lite.model_maker.third_party.efficientdet.dataset import tfrecord_util\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "SETS = ['train', 'val', 'trainval', 'test']\n",
        "YEARS = ['VOC2007', 'VOC2012', 'merged']\n",
        "\n",
        "pascal_label_map_dict = {\n",
        "    'background': 0,\n",
        "    'aeroplane': 1,\n",
        "    'bicycle': 2,\n",
        "    'bird': 3,\n",
        "    'boat': 4,\n",
        "    'bottle': 5,\n",
        "    'bus': 6,\n",
        "    'car': 7,\n",
        "    'cat': 8,\n",
        "    'chair': 9,\n",
        "    'cow': 10,\n",
        "    'diningtable': 11,\n",
        "    'dog': 12,\n",
        "    'horse': 13,\n",
        "    'motorbike': 14,\n",
        "    'person': 15,\n",
        "    'pottedplant': 16,\n",
        "    'sheep': 17,\n",
        "    'sofa': 18,\n",
        "    'train': 19,\n",
        "    'tvmonitor': 20,\n",
        "}\n",
        "\n",
        "\n",
        "def define_flags():\n",
        "  \"\"\"Define the flags.\"\"\"\n",
        "  flags.DEFINE_string('data_dir', '',\n",
        "                      'Root directory to raw PASCAL VOC dataset.')\n",
        "  flags.DEFINE_string('set', 'train', 'Convert training set, validation set or '\n",
        "                      'merged set.')\n",
        "  flags.DEFINE_string('annotations_dir', 'Annotations',\n",
        "                      '(Relative) path to annotations directory.')\n",
        "  flags.DEFINE_string('year', 'VOC2007', 'Desired challenge year.')\n",
        "  flags.DEFINE_string('output_path', '', 'Path to output TFRecord and json.')\n",
        "  flags.DEFINE_string('label_map_json_path', None,\n",
        "                      'Path to label map json file with a dictionary.')\n",
        "  flags.DEFINE_boolean('ignore_difficult_instances', False, 'Whether to ignore '\n",
        "                       'difficult instances')\n",
        "  flags.DEFINE_integer('num_shards', 100, 'Number of shards for output file.')\n",
        "  flags.DEFINE_integer('num_images', None, 'Max number of imags to process.')\n",
        "\n",
        "\n",
        "class UniqueId(object):\n",
        "  \"\"\"Class to get the unique {image/ann}_id each time calling the functions.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.image_id = 0\n",
        "    self.ann_id = 0\n",
        "\n",
        "  def get_image_id(self):\n",
        "    self.image_id += 1\n",
        "    return self.image_id\n",
        "\n",
        "  def get_ann_id(self):\n",
        "    self.ann_id += 1\n",
        "    return self.ann_id\n",
        "\n",
        "\n",
        "def dict_to_tf_example(data,\n",
        "                       images_dir,\n",
        "                       label_map_dict,\n",
        "                       unique_id,\n",
        "                       ignore_difficult_instances=False,\n",
        "                       ann_json_dict=None):\n",
        "  \"\"\"Convert XML derived dict to tf.Example proto.\n",
        "\n",
        "  Notice that this function normalizes the bounding box coordinates provided\n",
        "  by the raw data.\n",
        "\n",
        "  Args:\n",
        "    data: dict holding PASCAL XML fields for a single image (obtained by running\n",
        "      tfrecord_util.recursive_parse_xml_to_dict)\n",
        "    images_dir: Path to the directory holding raw images.\n",
        "    label_map_dict: A map from string label names to integers ids.\n",
        "    unique_id: UniqueId object to get the unique {image/ann}_id for the image\n",
        "      and the annotations.\n",
        "    ignore_difficult_instances: Whether to skip difficult instances in the\n",
        "      dataset  (default: False).\n",
        "    ann_json_dict: annotation json dictionary.\n",
        "\n",
        "  Returns:\n",
        "    example: The converted tf.Example.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: if the image pointed to by data['filename'] is not a valid JPEG\n",
        "  \"\"\"\n",
        "\n",
        "  # classes.append(label_map_dict[obj['name']])\n",
        "  full_path = os.path.join(images_dir, data['filename'])\n",
        "  with tf.io.gfile.GFile(full_path, 'rb') as fid:\n",
        "    encoded_jpg = fid.read()\n",
        "  encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "  image = PIL.Image.open(encoded_jpg_io)\n",
        "  if image.format != 'JPEG':\n",
        "    raise ValueError('Image format not JPEG')\n",
        "  key = hashlib.sha256(encoded_jpg).hexdigest()\n",
        "\n",
        "  image_id = unique_id.get_image_id()\n",
        "\n",
        "  width = int(data['size']['width'])\n",
        "  height = int(data['size']['height'])\n",
        "  if ann_json_dict:\n",
        "    image = {\n",
        "        'file_name': data['filename'],\n",
        "        'height': height,\n",
        "        'width': width,\n",
        "        'id': image_id,\n",
        "    }\n",
        "    ann_json_dict['images'].append(image)\n",
        "\n",
        "  xmin = []\n",
        "  ymin = []\n",
        "  xmax = []\n",
        "  ymax = []\n",
        "  area = []\n",
        "  classes = []\n",
        "  classes_text = []\n",
        "  truncated = []\n",
        "  poses = []\n",
        "  difficult_obj = []\n",
        "  if 'object' in data:\n",
        "    for obj in data['object']:\n",
        "      if obj['difficult'] == 'Unspecified':\n",
        "        difficult = False\n",
        "      else:\n",
        "        difficult = bool(int(obj['difficult']))\n",
        "      if ignore_difficult_instances and difficult:\n",
        "        continue\n",
        "\n",
        "      difficult_obj.append(int(difficult))\n",
        "\n",
        "      xmin.append(float(obj['bndbox']['xmin']) / width)\n",
        "      ymin.append(float(obj['bndbox']['ymin']) / height)\n",
        "      xmax.append(float(obj['bndbox']['xmax']) / width)\n",
        "      ymax.append(float(obj['bndbox']['ymax']) / height)\n",
        "      area.append((xmax[-1] - xmin[-1]) * (ymax[-1] - ymin[-1]))\n",
        "      # hi\n",
        "      print(\"this?\")\n",
        "      #########################################################################\n",
        "\n",
        "      classes_text.append(obj['name'].encode('utf8'))\n",
        "    #   classes.append(label_map_dict[obj['name']])\n",
        "      classes.append(label_map[int(obj['name'])])\n",
        "\n",
        "      #########################################################################\n",
        "      if obj['truncated'] == 'Unspecified':\n",
        "        truncated.append(0)\n",
        "      else:\n",
        "        truncated.append(int(obj['truncated']))\n",
        "      poses.append(obj['pose'].encode('utf8'))\n",
        "\n",
        "      if ann_json_dict:\n",
        "        abs_xmin = int(obj['bndbox']['xmin'])\n",
        "        abs_ymin = int(obj['bndbox']['ymin'])\n",
        "        abs_xmax = int(obj['bndbox']['xmax'])\n",
        "        abs_ymax = int(obj['bndbox']['ymax'])\n",
        "        abs_width = abs_xmax - abs_xmin\n",
        "        abs_height = abs_ymax - abs_ymin\n",
        "        ann = {\n",
        "            'area': abs_width * abs_height,\n",
        "            'iscrowd': 0,\n",
        "            'image_id': image_id,\n",
        "            'bbox': [abs_xmin, abs_ymin, abs_width, abs_height],\n",
        "            'category_id': label_map_dict[obj['name']],\n",
        "            'id': unique_id.get_ann_id(),\n",
        "            'ignore': 0,\n",
        "            'segmentation': [],\n",
        "        }\n",
        "        ann_json_dict['annotations'].append(ann)\n",
        "\n",
        "  example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "          feature={\n",
        "              'image/height':\n",
        "                  tfrecord_util.int64_feature(height),\n",
        "              'image/width':\n",
        "                  tfrecord_util.int64_feature(width),\n",
        "              'image/filename':\n",
        "                  tfrecord_util.bytes_feature(data['filename'].encode('utf8')),\n",
        "              'image/source_id':\n",
        "                  tfrecord_util.bytes_feature(str(image_id).encode('utf8')),\n",
        "              'image/key/sha256':\n",
        "                  tfrecord_util.bytes_feature(key.encode('utf8')),\n",
        "              'image/encoded':\n",
        "                  tfrecord_util.bytes_feature(encoded_jpg),\n",
        "              'image/format':\n",
        "                  tfrecord_util.bytes_feature('jpeg'.encode('utf8')),\n",
        "              'image/object/bbox/xmin':\n",
        "                  tfrecord_util.float_list_feature(xmin),\n",
        "              'image/object/bbox/xmax':\n",
        "                  tfrecord_util.float_list_feature(xmax),\n",
        "              'image/object/bbox/ymin':\n",
        "                  tfrecord_util.float_list_feature(ymin),\n",
        "              'image/object/bbox/ymax':\n",
        "                  tfrecord_util.float_list_feature(ymax),\n",
        "              'image/object/area':\n",
        "                  tfrecord_util.float_list_feature(area),\n",
        "              'image/object/class/text':\n",
        "                  tfrecord_util.bytes_list_feature(classes_text),\n",
        "              'image/object/class/label':\n",
        "                  tfrecord_util.int64_list_feature(classes),\n",
        "              'image/object/difficult':\n",
        "                  tfrecord_util.int64_list_feature(difficult_obj),\n",
        "              'image/object/truncated':\n",
        "                  tfrecord_util.int64_list_feature(truncated),\n",
        "              'image/object/view':\n",
        "                  tfrecord_util.bytes_list_feature(poses),\n",
        "          }))\n",
        "  return example\n",
        "\n",
        "\n",
        "def main(_):\n",
        "  if FLAGS.set not in SETS:\n",
        "    raise ValueError('set must be in : {}'.format(SETS))\n",
        "  if FLAGS.year not in YEARS:\n",
        "    raise ValueError('year must be in : {}'.format(YEARS))\n",
        "  if not FLAGS.output_path:\n",
        "    raise ValueError('output_path cannot be empty.')\n",
        "\n",
        "  data_dir = FLAGS.data_dir\n",
        "  years = ['VOC2007', 'VOC2012']\n",
        "  if FLAGS.year != 'merged':\n",
        "    years = [FLAGS.year]\n",
        "\n",
        "  output_dir = os.path.dirname(FLAGS.output_path)\n",
        "  if not tf.io.gfile.exists(output_dir):\n",
        "    tf.io.gfile.makedirs(output_dir)\n",
        "  logging.info('Writing to output directory: %s', output_dir)\n",
        "\n",
        "  writers = [\n",
        "      tf.io.TFRecordWriter(FLAGS.output_path + '-%05d-of-%05d.tfrecord' %\n",
        "                           (i, FLAGS.num_shards))\n",
        "      for i in range(FLAGS.num_shards)\n",
        "  ]\n",
        "\n",
        "  if FLAGS.label_map_json_path:\n",
        "    with tf.io.gfile.GFile(FLAGS.label_map_json_path, 'rb') as f:\n",
        "      label_map_dict = json.load(f)\n",
        "  else:\n",
        "    label_map_dict = pascal_label_map_dict\n",
        "\n",
        "  ann_json_dict = {\n",
        "      'images': [],\n",
        "      'type': 'instances',\n",
        "      'annotations': [],\n",
        "      'categories': []\n",
        "  }\n",
        "\n",
        "  unique_id = UniqueId()\n",
        "  for year in years:\n",
        "    example_class = list(label_map_dict.keys())[1]\n",
        "    examples_path = os.path.join(data_dir, year, 'ImageSets', 'Main',\n",
        "                                 example_class + '_' + FLAGS.set + '.txt')\n",
        "    examples_list = tfrecord_util.read_examples_list(examples_path)\n",
        "    annotations_dir = os.path.join(data_dir, year, FLAGS.annotations_dir)\n",
        "\n",
        "    for class_name, class_id in label_map_dict.items():\n",
        "      cls = {'supercategory': 'none', 'id': class_id, 'name': class_name}\n",
        "      ann_json_dict['categories'].append(cls)\n",
        "\n",
        "    logging.info('Reading from PASCAL %s dataset.', year)\n",
        "    for idx, example in enumerate(examples_list):\n",
        "      if FLAGS.num_images and idx >= FLAGS.num_images:\n",
        "        break\n",
        "      if idx % 100 == 0:\n",
        "        logging.info('On image %d of %d', idx, len(examples_list))\n",
        "      path = os.path.join(annotations_dir, example + '.xml')\n",
        "      with tf.io.gfile.GFile(path, 'r') as fid:\n",
        "        xml_str = fid.read()\n",
        "      xml = etree.fromstring(xml_str)\n",
        "      data = tfrecord_util.recursive_parse_xml_to_dict(xml)['annotation']\n",
        "\n",
        "      img_dir = os.path.join(FLAGS.data_dir, data['folder'], 'JPEGImages')\n",
        "\n",
        "      tf_example = dict_to_tf_example(\n",
        "          data,\n",
        "          img_dir,\n",
        "          label_map_dict,\n",
        "          unique_id,\n",
        "          FLAGS.ignore_difficult_instances,\n",
        "          ann_json_dict=ann_json_dict)\n",
        "      writers[idx % FLAGS.num_shards].write(tf_example.SerializeToString())\n",
        "\n",
        "  for writer in writers:\n",
        "    writer.close()\n",
        "\n",
        "  json_file_path = os.path.join(\n",
        "      os.path.dirname(FLAGS.output_path),\n",
        "      'json_' + os.path.basename(FLAGS.output_path) + '.json')\n",
        "  with tf.io.gfile.GFile(json_file_path, 'w') as f:\n",
        "    json.dump(ann_json_dict, f)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  define_flags()\n",
        "  app.run(main)\n"
      ],
      "metadata": {
        "id": "776byK9yINJP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}